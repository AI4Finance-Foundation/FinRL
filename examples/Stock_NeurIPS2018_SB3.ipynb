{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yfv52r2G33jY"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AI4Finance-Foundation/FinRL-Tutorials/blob/master/1-Introduction/Stock_NeurIPS2018_SB3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXaoZs2lh1hi"
   },
   "source": [
    "# Deep Reinforcement Learning for Stock Trading from Scratch: Multiple Stock Trading\n",
    "\n",
    "* **Pytorch Version** \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGunVt8oLCVS"
   },
   "source": [
    "# Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HOzAKQ-SLGX6"
   },
   "source": [
    "* [1. Task Description](#0)\n",
    "* [2. Install Python packages](#1)\n",
    "    * [2.1. Install Packages](#1.1)    \n",
    "    * [2.2. A List of Python Packages](#1.2)\n",
    "    * [2.3. Import Packages](#1.3)\n",
    "    * [2.4. Create Folders](#1.4)\n",
    "* [3. Download and Preprocess Data](#2)\n",
    "* [4. Preprocess Data](#3)        \n",
    "    * [4.1. Technical Indicators](#3.1)\n",
    "    * [4.2. Perform Feature Engineering](#3.2)\n",
    "* [5. Build Market Environment in OpenAI Gym-style](#4)  \n",
    "    * [5.1. Data Split](#4.1)  \n",
    "    * [5.3. Environment for Training](#4.2)    \n",
    "* [6. Train DRL Agents](#5)\n",
    "* [7. Backtesting Performance](#6)  \n",
    "    * [7.1. BackTestStats](#6.1)\n",
    "    * [7.2. BackTestPlot](#6.2)   \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sApkDlD9LIZv"
   },
   "source": [
    "<a id='0'></a>\n",
    "# Part 1. Task Discription"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HjLD2TZSLKZ-"
   },
   "source": [
    "We train a DRL agent for stock trading. This task is modeled as a Markov Decision Process (MDP), and the objective function is maximizing (expected) cumulative return.\n",
    "\n",
    "We specify the state-action-reward as follows:\n",
    "\n",
    "* **State s**: The state space represents an agent's perception of the market environment. Just like a human trader analyzing various information, here our agent passively observes many features and learns by interacting with the market environment (usually by replaying historical data).\n",
    "\n",
    "* **Action a**: The action space includes allowed actions that an agent can take at each state. For example, a ∈ {−1, 0, 1}, where −1, 0, 1 represent\n",
    "selling, holding, and buying. When an action operates multiple shares, a ∈{−k, ..., −1, 0, 1, ..., k}, e.g.. \"Buy\n",
    "10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or −10, respectively\n",
    "\n",
    "* **Reward function r(s, a, s′)**: Reward is an incentive for an agent to learn a better policy. For example, it can be the change of the portfolio value when taking a at state s and arriving at new state s',  i.e., r(s, a, s′) = v′ − v, where v′ and v represent the portfolio values at state s′ and s, respectively\n",
    "\n",
    "\n",
    "**Market environment**: 30 consituent stocks of Dow Jones Industrial Average (DJIA) index. Accessed at the starting date of the testing period.\n",
    "\n",
    "\n",
    "The data for this case study is obtained from Yahoo Finance API. The data contains Open-High-Low-Close price and volume.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ffsre789LY08"
   },
   "source": [
    "<a id='1'></a>\n",
    "# Part 2. Install Python Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uy5_PTmOh1hj"
   },
   "source": [
    "<a id='1.1'></a>\n",
    "## 2.1. Install packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mPT0ipYE28wL",
    "outputId": "e2b45f44-0d91-4182-b278-16f02b8ef98d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: swig in /home/james/miniconda3/envs/algo39/lib/python3.9/site-packages (4.1.1)\r\n",
      "Requirement already satisfied: wrds in /home/james/miniconda3/envs/algo39/lib/python3.9/site-packages (3.1.2)\r\n",
      "Requirement already satisfied: mock in /home/james/miniconda3/envs/algo39/lib/python3.9/site-packages (from wrds) (5.0.1)\r\n",
      "Requirement already satisfied: psycopg2-binary in /home/james/miniconda3/envs/algo39/lib/python3.9/site-packages (from wrds) (2.9.5)\r\n",
      "Requirement already satisfied: pandas in /home/james/miniconda3/envs/algo39/lib/python3.9/site-packages (from wrds) (1.5.2)\r\n",
      "Requirement already satisfied: sqlalchemy in /home/james/miniconda3/envs/algo39/lib/python3.9/site-packages (from wrds) (2.0.1)\r\n",
      "Requirement already satisfied: numpy in /home/james/miniconda3/envs/algo39/lib/python3.9/site-packages (from wrds) (1.24.1)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/james/miniconda3/envs/algo39/lib/python3.9/site-packages (from pandas->wrds) (2022.7.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/james/miniconda3/envs/algo39/lib/python3.9/site-packages (from pandas->wrds) (2.8.2)\r\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /home/james/miniconda3/envs/algo39/lib/python3.9/site-packages (from sqlalchemy->wrds) (4.4.0)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/james/miniconda3/envs/algo39/lib/python3.9/site-packages (from sqlalchemy->wrds) (2.0.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /home/james/miniconda3/envs/algo39/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->wrds) (1.16.0)\r\n",
      "Collecting pyportfolioopt\r\n",
      "  Downloading pyportfolioopt-1.5.4-py3-none-any.whl (61 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m61.9/61.9 kB\u001B[0m \u001B[31m3.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: scipy<2.0,>=1.3 in /home/james/miniconda3/envs/algo39/lib/python3.9/site-packages (from pyportfolioopt) (1.10.0)\r\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.22.4 in /home/james/miniconda3/envs/algo39/lib/python3.9/site-packages (from pyportfolioopt) (1.24.1)\r\n",
      "Requirement already satisfied: pandas>=0.19 in /home/james/miniconda3/envs/algo39/lib/python3.9/site-packages (from pyportfolioopt) (1.5.2)\r\n",
      "Collecting cvxpy<2.0.0,>=1.1.10\r\n",
      "  Downloading cvxpy-1.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m4.0/4.0 MB\u001B[0m \u001B[31m88.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting ecos>=2\r\n",
      "  Downloading ecos-2.0.12-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (220 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m220.1/220.1 kB\u001B[0m \u001B[31m82.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting scs>=1.1.6\r\n",
      "  Downloading scs-3.2.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.7 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m10.7/10.7 MB\u001B[0m \u001B[31m50.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m0:01\u001B[0mm\r\n",
      "\u001B[?25hRequirement already satisfied: setuptools<=64.0.2 in /home/james/miniconda3/envs/algo39/lib/python3.9/site-packages (from cvxpy<2.0.0,>=1.1.10->pyportfolioopt) (59.5.0)\r\n",
      "Collecting osqp>=0.4.1\r\n",
      "  Downloading osqp-0.6.2.post8-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (298 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m298.2/298.2 kB\u001B[0m \u001B[31m78.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: pytz>=2020.1 in /home/james/miniconda3/envs/algo39/lib/python3.9/site-packages (from pandas>=0.19->pyportfolioopt) (2022.7.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/james/miniconda3/envs/algo39/lib/python3.9/site-packages (from pandas>=0.19->pyportfolioopt) (2.8.2)\r\n",
      "Collecting qdldl\r\n",
      "  Downloading qdldl-0.1.5.post3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.0/1.0 MB\u001B[0m \u001B[31m98.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: six>=1.5 in /home/james/miniconda3/envs/algo39/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas>=0.19->pyportfolioopt) (1.16.0)\r\n",
      "Installing collected packages: scs, qdldl, ecos, osqp, cvxpy, pyportfolioopt\r\n",
      "Successfully installed cvxpy-1.3.0 ecos-2.0.12 osqp-0.6.2.post8 pyportfolioopt-1.5.4 qdldl-0.1.5.post3 scs-3.2.2\r\n"
     ]
    }
   ],
   "source": [
    "## install required packages\n",
    "!pip install swig\n",
    "!pip install wrds\n",
    "!pip install pyportfolioopt\n",
    "## install finrl library\n",
    "# !pip install git+https://github.com/AI4Finance-Foundation/FinRL.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "osBHhVysOEzi"
   },
   "source": [
    "\n",
    "<a id='1.2'></a>\n",
    "## 2.2. A list of Python packages \n",
    "* Yahoo Finance API\n",
    "* pandas\n",
    "* numpy\n",
    "* matplotlib\n",
    "* stockstats\n",
    "* OpenAI gym\n",
    "* stable-baselines\n",
    "* tensorflow\n",
    "* pyfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nGv01K8Sh1hn"
   },
   "source": [
    "<a id='1.3'></a>\n",
    "## 2.3. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lPqeTTwoh1hn",
    "outputId": "23c28589-9d6f-4b8b-bf9e-9822e4ccea90"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/james/miniconda3/envs/algo39/lib/python3.9/site-packages/pyfolio/pos.py:26: UserWarning: Module \"zipline.assets\" not found; mutltipliers will not be applied to position notionals.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.use('Agg')\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
    "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "from stable_baselines3.common.logger import configure\n",
    "from finrl.meta.data_processor import DataProcessor\n",
    "\n",
    "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
    "from pprint import pprint\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../FinRL\")\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2owTj985RW4"
   },
   "source": [
    "<a id='1.4'></a>\n",
    "## 2.4. Create Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "RtUc_ofKmpdy"
   },
   "outputs": [],
   "source": [
    "from finrl import config\n",
    "from finrl import config_tickers\n",
    "import os\n",
    "from finrl.main import check_and_make_directories\n",
    "from finrl.config import (\n",
    "    DATA_SAVE_DIR,\n",
    "    TRAINED_MODEL_DIR,\n",
    "    TENSORBOARD_LOG_DIR,\n",
    "    RESULTS_DIR,\n",
    "    INDICATORS,\n",
    "    TRAIN_START_DATE,\n",
    "    TRAIN_END_DATE,\n",
    "    TEST_START_DATE,\n",
    "    TEST_END_DATE,\n",
    "    TRADE_START_DATE,\n",
    "    TRADE_END_DATE,\n",
    ")\n",
    "check_and_make_directories([DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A289rQWMh1hq"
   },
   "source": [
    "<a id='2'></a>\n",
    "# Part 3. Download Data\n",
    "Yahoo Finance provides stock data, financial news, financial reports, etc. Yahoo Finance is free.\n",
    "* FinRL uses a class **YahooDownloader** in FinRL-Meta to fetch data via Yahoo Finance API\n",
    "* Call Limit: Using the Public API (without authentication), you are limited to 2,000 requests per hour per IP (or up to a total of 48,000 requests a day)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NPeQ7iS-LoMm"
   },
   "source": [
    "\n",
    "\n",
    "-----\n",
    "class YahooDownloader:\n",
    "    Retrieving daily stock data from\n",
    "    Yahoo Finance API\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "        start_date : str\n",
    "            start date of the data (modified from config.py)\n",
    "        end_date : str\n",
    "            end date of the data (modified from config.py)\n",
    "        ticker_list : list\n",
    "            a list of stock tickers (modified from config.py)\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    fetch_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "h3XJnvrbLp-C",
    "outputId": "43a6df4b-1a4f-4835-a7d3-4f4da695f474"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'2020-07-31'"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from config.py, TRAIN_START_DATE is a string\n",
    "TRAIN_START_DATE\n",
    "# from config.py, TRAIN_END_DATE is a string\n",
    "TRAIN_END_DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "FUnY8WEfLq3C"
   },
   "outputs": [],
   "source": [
    "TRAIN_START_DATE = '2009-01-01'\n",
    "TRAIN_END_DATE = '2020-07-01'\n",
    "TRADE_START_DATE = '2020-07-01'\n",
    "TRADE_END_DATE = '2021-10-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yCKm4om-s9kE",
    "outputId": "9012549f-ac6c-48d3-9254-b162a53930a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (94331, 8)\n"
     ]
    }
   ],
   "source": [
    "df = YahooDownloader(start_date = TRAIN_START_DATE,\n",
    "                     end_date = TRADE_END_DATE,\n",
    "                     ticker_list = config_tickers.DOW_30_TICKER).fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JzqRRTOX6aFu",
    "outputId": "c39fd69d-4815-416d-8bef-54dc7c6abcbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AXP', 'AMGN', 'AAPL', 'BA', 'CAT', 'CSCO', 'CVX', 'GS', 'HD', 'HON', 'IBM', 'INTC', 'JNJ', 'KO', 'JPM', 'MCD', 'MMM', 'MRK', 'MSFT', 'NKE', 'PG', 'TRV', 'UNH', 'CRM', 'VZ', 'V', 'WBA', 'WMT', 'DIS', 'DOW']\n"
     ]
    }
   ],
   "source": [
    "print(config_tickers.DOW_30_TICKER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CV3HrZHLh1hy",
    "outputId": "5f69723b-2a5d-4d64-87c5-3a6d3abecd3c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(94331, 8)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "4hYkeaPiICHS",
    "outputId": "7adbffad-04bf-4b83-d47e-6b25cb56efa6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "         date       open       high        low      close     volume   tic  \\\n0  2009-01-02   3.067143   3.251429   3.041429   2.762747  746015200  AAPL   \n1  2009-01-02  58.590000  59.080002  57.750000  44.219177    6547900  AMGN   \n2  2009-01-02  18.570000  19.520000  18.400000  15.365301   10955700   AXP   \n3  2009-01-02  42.799999  45.560001  42.779999  33.941093    7010200    BA   \n4  2009-01-02  44.910000  46.980000  44.709999  31.579334    7117200   CAT   \n\n   day  \n0    4  \n1    4  \n2    4  \n3    4  \n4    4  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>volume</th>\n      <th>tic</th>\n      <th>day</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2009-01-02</td>\n      <td>3.067143</td>\n      <td>3.251429</td>\n      <td>3.041429</td>\n      <td>2.762747</td>\n      <td>746015200</td>\n      <td>AAPL</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2009-01-02</td>\n      <td>58.590000</td>\n      <td>59.080002</td>\n      <td>57.750000</td>\n      <td>44.219177</td>\n      <td>6547900</td>\n      <td>AMGN</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2009-01-02</td>\n      <td>18.570000</td>\n      <td>19.520000</td>\n      <td>18.400000</td>\n      <td>15.365301</td>\n      <td>10955700</td>\n      <td>AXP</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2009-01-02</td>\n      <td>42.799999</td>\n      <td>45.560001</td>\n      <td>42.779999</td>\n      <td>33.941093</td>\n      <td>7010200</td>\n      <td>BA</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2009-01-02</td>\n      <td>44.910000</td>\n      <td>46.980000</td>\n      <td>44.709999</td>\n      <td>31.579334</td>\n      <td>7117200</td>\n      <td>CAT</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(['date','tic'],ignore_index=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uqC6c40Zh1iH"
   },
   "source": [
    "# Part 4: Preprocess Data\n",
    "We need to check for missing data and do feature engineering to convert the data point into a state.\n",
    "* **Adding technical indicators**. In practical trading, various information needs to be taken into account, such as historical prices, current holding shares, technical indicators, etc. Here, we demonstrate two trend-following technical indicators: MACD and RSI.\n",
    "* **Adding turbulence index**. Risk-aversion reflects whether an investor prefers to protect the capital. It also influences one's trading strategy when facing different market volatility level. To control the risk in a worst-case scenario, such as financial crisis of 2007–2008, FinRL employs the turbulence index that measures extreme fluctuation of asset price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PmKP-1ii3RLS",
    "outputId": "da44c66b-ec26-4950-c85c-2bd1aa80d8e6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/home/james/Dropbox/Investing/Personal_Algo_Trading_Practice/FinRL_JDB/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (3229, 8)\n",
      "Successfully added vix\n",
      "Successfully added turbulence index\n"
     ]
    }
   ],
   "source": [
    "fe = FeatureEngineer(\n",
    "                    use_technical_indicator=True,\n",
    "                    tech_indicator_list = INDICATORS,\n",
    "                    use_vix=True,\n",
    "                    use_turbulence=True,\n",
    "                    user_defined_feature = False)\n",
    "\n",
    "processed = fe.preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Kixon2tR3RLT"
   },
   "outputs": [],
   "source": [
    "list_ticker = processed[\"tic\"].unique().tolist()\n",
    "list_date = list(pd.date_range(processed['date'].min(),processed['date'].max()).astype(str))\n",
    "combination = list(itertools.product(list_date,list_ticker))\n",
    "\n",
    "processed_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(processed,on=[\"date\",\"tic\"],how=\"left\")\n",
    "processed_full = processed_full[processed_full['date'].isin(processed['date'])]\n",
    "processed_full = processed_full.sort_values(['date','tic'])\n",
    "\n",
    "processed_full = processed_full.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 601
    },
    "id": "grvhGJJII3Xn",
    "outputId": "935e319f-b7d8-4ed5-971d-05ef8c92e78b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "         date   tic       open       high        low      close       volume  \\\n0  2009-01-02  AAPL   3.067143   3.251429   3.041429   2.762747  746015200.0   \n1  2009-01-02  AMGN  58.590000  59.080002  57.750000  44.219177    6547900.0   \n2  2009-01-02   AXP  18.570000  19.520000  18.400000  15.365301   10955700.0   \n3  2009-01-02    BA  42.799999  45.560001  42.779999  33.941093    7010200.0   \n4  2009-01-02   CAT  44.910000  46.980000  44.709999  31.579334    7117200.0   \n5  2009-01-02   CRM   8.025000   8.550000   7.912500   8.505000    4069200.0   \n6  2009-01-02  CSCO  16.410000  17.000000  16.250000  11.948333   40980600.0   \n7  2009-01-02   CVX  74.230003  77.300003  73.580002  44.063293   13695900.0   \n8  2009-01-02   DIS  22.760000  24.030001  22.500000  20.597498    9796600.0   \n9  2009-01-02    GS  84.019997  87.620003  82.190002  69.747620   14088500.0   \n\n   day  macd   boll_ub  boll_lb  rsi_30     cci_30  dx_30  close_30_sma  \\\n0  4.0   0.0  2.985943  2.65615   100.0  66.666667  100.0      2.762747   \n1  4.0   0.0  2.985943  2.65615   100.0  66.666667  100.0     44.219177   \n2  4.0   0.0  2.985943  2.65615   100.0  66.666667  100.0     15.365301   \n3  4.0   0.0  2.985943  2.65615   100.0  66.666667  100.0     33.941093   \n4  4.0   0.0  2.985943  2.65615   100.0  66.666667  100.0     31.579334   \n5  4.0   0.0  2.985943  2.65615   100.0  66.666667  100.0      8.505000   \n6  4.0   0.0  2.985943  2.65615   100.0  66.666667  100.0     11.948333   \n7  4.0   0.0  2.985943  2.65615   100.0  66.666667  100.0     44.063293   \n8  4.0   0.0  2.985943  2.65615   100.0  66.666667  100.0     20.597498   \n9  4.0   0.0  2.985943  2.65615   100.0  66.666667  100.0     69.747620   \n\n   close_60_sma        vix  turbulence  \n0      2.762747  39.189999         0.0  \n1     44.219177  39.189999         0.0  \n2     15.365301  39.189999         0.0  \n3     33.941093  39.189999         0.0  \n4     31.579334  39.189999         0.0  \n5      8.505000  39.189999         0.0  \n6     11.948333  39.189999         0.0  \n7     44.063293  39.189999         0.0  \n8     20.597498  39.189999         0.0  \n9     69.747620  39.189999         0.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>tic</th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>volume</th>\n      <th>day</th>\n      <th>macd</th>\n      <th>boll_ub</th>\n      <th>boll_lb</th>\n      <th>rsi_30</th>\n      <th>cci_30</th>\n      <th>dx_30</th>\n      <th>close_30_sma</th>\n      <th>close_60_sma</th>\n      <th>vix</th>\n      <th>turbulence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2009-01-02</td>\n      <td>AAPL</td>\n      <td>3.067143</td>\n      <td>3.251429</td>\n      <td>3.041429</td>\n      <td>2.762747</td>\n      <td>746015200.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>2.985943</td>\n      <td>2.65615</td>\n      <td>100.0</td>\n      <td>66.666667</td>\n      <td>100.0</td>\n      <td>2.762747</td>\n      <td>2.762747</td>\n      <td>39.189999</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2009-01-02</td>\n      <td>AMGN</td>\n      <td>58.590000</td>\n      <td>59.080002</td>\n      <td>57.750000</td>\n      <td>44.219177</td>\n      <td>6547900.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>2.985943</td>\n      <td>2.65615</td>\n      <td>100.0</td>\n      <td>66.666667</td>\n      <td>100.0</td>\n      <td>44.219177</td>\n      <td>44.219177</td>\n      <td>39.189999</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2009-01-02</td>\n      <td>AXP</td>\n      <td>18.570000</td>\n      <td>19.520000</td>\n      <td>18.400000</td>\n      <td>15.365301</td>\n      <td>10955700.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>2.985943</td>\n      <td>2.65615</td>\n      <td>100.0</td>\n      <td>66.666667</td>\n      <td>100.0</td>\n      <td>15.365301</td>\n      <td>15.365301</td>\n      <td>39.189999</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2009-01-02</td>\n      <td>BA</td>\n      <td>42.799999</td>\n      <td>45.560001</td>\n      <td>42.779999</td>\n      <td>33.941093</td>\n      <td>7010200.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>2.985943</td>\n      <td>2.65615</td>\n      <td>100.0</td>\n      <td>66.666667</td>\n      <td>100.0</td>\n      <td>33.941093</td>\n      <td>33.941093</td>\n      <td>39.189999</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2009-01-02</td>\n      <td>CAT</td>\n      <td>44.910000</td>\n      <td>46.980000</td>\n      <td>44.709999</td>\n      <td>31.579334</td>\n      <td>7117200.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>2.985943</td>\n      <td>2.65615</td>\n      <td>100.0</td>\n      <td>66.666667</td>\n      <td>100.0</td>\n      <td>31.579334</td>\n      <td>31.579334</td>\n      <td>39.189999</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2009-01-02</td>\n      <td>CRM</td>\n      <td>8.025000</td>\n      <td>8.550000</td>\n      <td>7.912500</td>\n      <td>8.505000</td>\n      <td>4069200.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>2.985943</td>\n      <td>2.65615</td>\n      <td>100.0</td>\n      <td>66.666667</td>\n      <td>100.0</td>\n      <td>8.505000</td>\n      <td>8.505000</td>\n      <td>39.189999</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2009-01-02</td>\n      <td>CSCO</td>\n      <td>16.410000</td>\n      <td>17.000000</td>\n      <td>16.250000</td>\n      <td>11.948333</td>\n      <td>40980600.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>2.985943</td>\n      <td>2.65615</td>\n      <td>100.0</td>\n      <td>66.666667</td>\n      <td>100.0</td>\n      <td>11.948333</td>\n      <td>11.948333</td>\n      <td>39.189999</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2009-01-02</td>\n      <td>CVX</td>\n      <td>74.230003</td>\n      <td>77.300003</td>\n      <td>73.580002</td>\n      <td>44.063293</td>\n      <td>13695900.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>2.985943</td>\n      <td>2.65615</td>\n      <td>100.0</td>\n      <td>66.666667</td>\n      <td>100.0</td>\n      <td>44.063293</td>\n      <td>44.063293</td>\n      <td>39.189999</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2009-01-02</td>\n      <td>DIS</td>\n      <td>22.760000</td>\n      <td>24.030001</td>\n      <td>22.500000</td>\n      <td>20.597498</td>\n      <td>9796600.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>2.985943</td>\n      <td>2.65615</td>\n      <td>100.0</td>\n      <td>66.666667</td>\n      <td>100.0</td>\n      <td>20.597498</td>\n      <td>20.597498</td>\n      <td>39.189999</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2009-01-02</td>\n      <td>GS</td>\n      <td>84.019997</td>\n      <td>87.620003</td>\n      <td>82.190002</td>\n      <td>69.747620</td>\n      <td>14088500.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>2.985943</td>\n      <td>2.65615</td>\n      <td>100.0</td>\n      <td>66.666667</td>\n      <td>100.0</td>\n      <td>69.747620</td>\n      <td>69.747620</td>\n      <td>39.189999</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_full.sort_values(['date','tic'],ignore_index=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "5vdORQ384Qx-"
   },
   "outputs": [],
   "source": [
    "mvo_df = processed_full.sort_values(['date','tic'],ignore_index=True)[['date','tic','close']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-QsYaY0Dh1iw"
   },
   "source": [
    "<a id='4'></a>\n",
    "# Part 5. Build A Market Environment in OpenAI Gym-style\n",
    "The training process involves observing stock price change, taking an action and reward's calculation. By interacting with the market environment, the agent will eventually derive a trading strategy that may maximize (expected) rewards.\n",
    "\n",
    "Our market environment, based on OpenAI Gym, simulates stock markets with historical market data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5TOhcryx44bb"
   },
   "source": [
    "## Data Split\n",
    "We split the data into training set and testing set as follows:\n",
    "\n",
    "Training data period: 2009-01-01 to 2020-07-01\n",
    "\n",
    "Trading data period: 2020-07-01 to 2021-10-31\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W0qaVGjLtgbI",
    "outputId": "99d9a9eb-68ca-4e0b-f29a-16aeefe05693"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83897\n",
      "9744\n"
     ]
    }
   ],
   "source": [
    "train = data_split(processed_full, TRAIN_START_DATE,TRAIN_END_DATE)\n",
    "trade = data_split(processed_full, TRADE_START_DATE,TRADE_END_DATE)\n",
    "print(len(train))\n",
    "print(len(trade))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "p52zNCOhTtLR",
    "outputId": "22263b87-b851-4d0d-a584-8572bca8ff0d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "            date  tic        open        high         low       close  \\\n2892  2020-06-30  UNH  288.570007  296.450012  287.660004  284.978760   \n2892  2020-06-30    V  191.490005  193.750000  190.160004  189.975403   \n2892  2020-06-30   VZ   54.919998   55.290001   54.360001   48.169003   \n2892  2020-06-30  WBA   42.119999   42.580002   41.759998   38.128487   \n2892  2020-06-30  WMT  119.220001  120.129997  118.540001  115.184013   \n\n          volume  day      macd     boll_ub     boll_lb     rsi_30     cci_30  \\\n2892   2932900.0  1.0 -0.019284  300.970806  268.613862  52.413055 -25.914799   \n2892   9040100.0  1.0  1.044597  197.956679  184.302275  53.021042 -51.589193   \n2892  17414800.0  1.0 -0.417955   51.555481   46.593789  48.097017 -51.186866   \n2892   4782100.0  1.0 -0.082035   41.619004   35.639081  48.830183 -14.575663   \n2892   6836400.0  1.0 -0.879409  118.508931  112.593779  48.159681 -69.964692   \n\n         dx_30  close_30_sma  close_60_sma    vix  turbulence  \n2892  1.846804    285.220265    278.269268  30.43   12.918738  \n2892  2.013358    190.720192    180.952012  30.43   12.918738  \n2892  8.508886     48.776546     49.209271  30.43   12.918738  \n2892  1.500723     38.225631     38.030221  30.43   12.918738  \n2892  3.847271    116.836412    118.756426  30.43   12.918738  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>tic</th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>volume</th>\n      <th>day</th>\n      <th>macd</th>\n      <th>boll_ub</th>\n      <th>boll_lb</th>\n      <th>rsi_30</th>\n      <th>cci_30</th>\n      <th>dx_30</th>\n      <th>close_30_sma</th>\n      <th>close_60_sma</th>\n      <th>vix</th>\n      <th>turbulence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2892</th>\n      <td>2020-06-30</td>\n      <td>UNH</td>\n      <td>288.570007</td>\n      <td>296.450012</td>\n      <td>287.660004</td>\n      <td>284.978760</td>\n      <td>2932900.0</td>\n      <td>1.0</td>\n      <td>-0.019284</td>\n      <td>300.970806</td>\n      <td>268.613862</td>\n      <td>52.413055</td>\n      <td>-25.914799</td>\n      <td>1.846804</td>\n      <td>285.220265</td>\n      <td>278.269268</td>\n      <td>30.43</td>\n      <td>12.918738</td>\n    </tr>\n    <tr>\n      <th>2892</th>\n      <td>2020-06-30</td>\n      <td>V</td>\n      <td>191.490005</td>\n      <td>193.750000</td>\n      <td>190.160004</td>\n      <td>189.975403</td>\n      <td>9040100.0</td>\n      <td>1.0</td>\n      <td>1.044597</td>\n      <td>197.956679</td>\n      <td>184.302275</td>\n      <td>53.021042</td>\n      <td>-51.589193</td>\n      <td>2.013358</td>\n      <td>190.720192</td>\n      <td>180.952012</td>\n      <td>30.43</td>\n      <td>12.918738</td>\n    </tr>\n    <tr>\n      <th>2892</th>\n      <td>2020-06-30</td>\n      <td>VZ</td>\n      <td>54.919998</td>\n      <td>55.290001</td>\n      <td>54.360001</td>\n      <td>48.169003</td>\n      <td>17414800.0</td>\n      <td>1.0</td>\n      <td>-0.417955</td>\n      <td>51.555481</td>\n      <td>46.593789</td>\n      <td>48.097017</td>\n      <td>-51.186866</td>\n      <td>8.508886</td>\n      <td>48.776546</td>\n      <td>49.209271</td>\n      <td>30.43</td>\n      <td>12.918738</td>\n    </tr>\n    <tr>\n      <th>2892</th>\n      <td>2020-06-30</td>\n      <td>WBA</td>\n      <td>42.119999</td>\n      <td>42.580002</td>\n      <td>41.759998</td>\n      <td>38.128487</td>\n      <td>4782100.0</td>\n      <td>1.0</td>\n      <td>-0.082035</td>\n      <td>41.619004</td>\n      <td>35.639081</td>\n      <td>48.830183</td>\n      <td>-14.575663</td>\n      <td>1.500723</td>\n      <td>38.225631</td>\n      <td>38.030221</td>\n      <td>30.43</td>\n      <td>12.918738</td>\n    </tr>\n    <tr>\n      <th>2892</th>\n      <td>2020-06-30</td>\n      <td>WMT</td>\n      <td>119.220001</td>\n      <td>120.129997</td>\n      <td>118.540001</td>\n      <td>115.184013</td>\n      <td>6836400.0</td>\n      <td>1.0</td>\n      <td>-0.879409</td>\n      <td>118.508931</td>\n      <td>112.593779</td>\n      <td>48.159681</td>\n      <td>-69.964692</td>\n      <td>3.847271</td>\n      <td>116.836412</td>\n      <td>118.756426</td>\n      <td>30.43</td>\n      <td>12.918738</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "k9zU9YaTTvFq",
    "outputId": "f8289fe9-674a-4456-aaea-9d021ddbb5a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "         date   tic        open        high         low       close  \\\n0  2020-07-01  AAPL   91.279999   91.839996   90.977501   89.631218   \n0  2020-07-01  AMGN  235.520004  256.230011  232.580002  236.683334   \n0  2020-07-01   AXP   95.250000   96.959999   93.639999   91.078461   \n0  2020-07-01    BA  185.880005  190.610001  180.039993  180.320007   \n0  2020-07-01   CAT  129.380005  129.399994  125.879997  118.455795   \n\n        volume  day      macd     boll_ub     boll_lb     rsi_30      cci_30  \\\n0  110737200.0  2.0  3.005436   92.417426   79.936126  62.807160  107.496733   \n0    6575800.0  2.0  3.583839  229.038886  197.319561  61.279648  271.050749   \n0    3301000.0  2.0 -0.384903  109.215325   86.798782  48.504812  -66.306199   \n0   49036700.0  2.0  5.443193  220.721139  160.932863  50.925771   24.220608   \n0    2807800.0  2.0  1.249468  128.246938  111.290109  52.865421   35.692984   \n\n       dx_30  close_30_sma  close_60_sma        vix  turbulence  \n0  29.730532     83.678529     77.481209  28.620001   53.068034  \n0  46.806139    211.753605    212.811100  28.620001   53.068034  \n0   3.142448     96.180268     89.702837  28.620001   53.068034  \n0  15.932920    176.472335    155.614168  28.620001   53.068034  \n0  14.457404    117.239536    111.578319  28.620001   53.068034  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>tic</th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>volume</th>\n      <th>day</th>\n      <th>macd</th>\n      <th>boll_ub</th>\n      <th>boll_lb</th>\n      <th>rsi_30</th>\n      <th>cci_30</th>\n      <th>dx_30</th>\n      <th>close_30_sma</th>\n      <th>close_60_sma</th>\n      <th>vix</th>\n      <th>turbulence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020-07-01</td>\n      <td>AAPL</td>\n      <td>91.279999</td>\n      <td>91.839996</td>\n      <td>90.977501</td>\n      <td>89.631218</td>\n      <td>110737200.0</td>\n      <td>2.0</td>\n      <td>3.005436</td>\n      <td>92.417426</td>\n      <td>79.936126</td>\n      <td>62.807160</td>\n      <td>107.496733</td>\n      <td>29.730532</td>\n      <td>83.678529</td>\n      <td>77.481209</td>\n      <td>28.620001</td>\n      <td>53.068034</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>2020-07-01</td>\n      <td>AMGN</td>\n      <td>235.520004</td>\n      <td>256.230011</td>\n      <td>232.580002</td>\n      <td>236.683334</td>\n      <td>6575800.0</td>\n      <td>2.0</td>\n      <td>3.583839</td>\n      <td>229.038886</td>\n      <td>197.319561</td>\n      <td>61.279648</td>\n      <td>271.050749</td>\n      <td>46.806139</td>\n      <td>211.753605</td>\n      <td>212.811100</td>\n      <td>28.620001</td>\n      <td>53.068034</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>2020-07-01</td>\n      <td>AXP</td>\n      <td>95.250000</td>\n      <td>96.959999</td>\n      <td>93.639999</td>\n      <td>91.078461</td>\n      <td>3301000.0</td>\n      <td>2.0</td>\n      <td>-0.384903</td>\n      <td>109.215325</td>\n      <td>86.798782</td>\n      <td>48.504812</td>\n      <td>-66.306199</td>\n      <td>3.142448</td>\n      <td>96.180268</td>\n      <td>89.702837</td>\n      <td>28.620001</td>\n      <td>53.068034</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>2020-07-01</td>\n      <td>BA</td>\n      <td>185.880005</td>\n      <td>190.610001</td>\n      <td>180.039993</td>\n      <td>180.320007</td>\n      <td>49036700.0</td>\n      <td>2.0</td>\n      <td>5.443193</td>\n      <td>220.721139</td>\n      <td>160.932863</td>\n      <td>50.925771</td>\n      <td>24.220608</td>\n      <td>15.932920</td>\n      <td>176.472335</td>\n      <td>155.614168</td>\n      <td>28.620001</td>\n      <td>53.068034</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>2020-07-01</td>\n      <td>CAT</td>\n      <td>129.380005</td>\n      <td>129.399994</td>\n      <td>125.879997</td>\n      <td>118.455795</td>\n      <td>2807800.0</td>\n      <td>2.0</td>\n      <td>1.249468</td>\n      <td>128.246938</td>\n      <td>111.290109</td>\n      <td>52.865421</td>\n      <td>35.692984</td>\n      <td>14.457404</td>\n      <td>117.239536</td>\n      <td>111.578319</td>\n      <td>28.620001</td>\n      <td>53.068034</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zYN573SOHhxG",
    "outputId": "e8e3426a-3f41-4153-c5ff-80b9a997c9ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['macd',\n 'boll_ub',\n 'boll_lb',\n 'rsi_30',\n 'cci_30',\n 'dx_30',\n 'close_30_sma',\n 'close_60_sma']"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INDICATORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q2zqII8rMIqn",
    "outputId": "0d415071-8d51-42f9-b141-f2122e272da6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 29, State Space: 291\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "AWyp84Ltto19"
   },
   "outputs": [],
   "source": [
    "buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
    "num_stock_shares = [0] * stock_dimension\n",
    "\n",
    "env_kwargs = {\n",
    "    \"hmax\": 100,\n",
    "    \"initial_amount\": 1000000,\n",
    "    \"num_stock_shares\": num_stock_shares,\n",
    "    \"buy_cost_pct\": buy_cost_list,\n",
    "    \"sell_cost_pct\": sell_cost_list,\n",
    "    \"state_space\": state_space,\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"tech_indicator_list\": INDICATORS,\n",
    "    \"action_space\": stock_dimension,\n",
    "    \"reward_scaling\": 1e-4\n",
    "}\n",
    "\n",
    "\n",
    "e_train_gym = StockTradingEnv(df = train, **env_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64EoqOrQjiVf"
   },
   "source": [
    "## Environment for Training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xwSvvPjutpqS",
    "outputId": "78c63dfc-e3c8-4d7a-f807-4ce7058d5384"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
     ]
    }
   ],
   "source": [
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(type(env_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMNR5nHjh1iz"
   },
   "source": [
    "<a id='5'></a>\n",
    "# Part 6: Train DRL Agents\n",
    "* The DRL algorithms are from **Stable Baselines 3**. Users are also encouraged to try **ElegantRL** and **Ray RLlib**.\n",
    "* FinRL includes fine-tuned standard DRL algorithms, such as DQN, DDPG, Multi-Agent DDPG, PPO, SAC, A2C and TD3. We also allow users to\n",
    "design their own DRL algorithms by adapting these DRL algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "364PsqckttcQ"
   },
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "\n",
    "if_using_a2c = True\n",
    "if_using_ddpg = True\n",
    "if_using_ppo = True\n",
    "if_using_td3 = True\n",
    "if_using_sac = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YDmqOyF9h1iz"
   },
   "source": [
    "### Agent Training: 5 algorithms (A2C, DDPG, PPO, TD3, SAC)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uijiWgkuh1jB"
   },
   "source": [
    "### Agent 1: A2C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GUCnkn-HIbmj",
    "outputId": "8be899ae-c772-46fd-e613-92dacfa9ed4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-06 05:15:25.853320: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-06 05:15:25.937454: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to results/a2c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-06 05:15:26.240615: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/james/miniconda3/envs/algo39/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2023-02-06 05:15:26.240655: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/james/miniconda3/envs/algo39/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2023-02-06 05:15:26.240658: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "model_a2c = agent.get_model(\"a2c\")\n",
    "\n",
    "if if_using_a2c:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/a2c'\n",
    "  new_logger_a2c = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_a2c.set_logger(new_logger_a2c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0GVpkWGqH4-D",
    "outputId": "4772e493-7857-4ea6-e091-a8fbc665f06b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 156         |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 3           |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41.2       |\n",
      "|    explained_variance | 0.576       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 99          |\n",
      "|    policy_loss        | -1.02       |\n",
      "|    reward             | -0.08586009 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 0.0527      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 172        |\n",
      "|    iterations         | 200        |\n",
      "|    time_elapsed       | 5          |\n",
      "|    total_timesteps    | 1000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 199        |\n",
      "|    policy_loss        | -32.7      |\n",
      "|    reward             | -2.3532257 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 2.33       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 183       |\n",
      "|    iterations         | 300       |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 1500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 299       |\n",
      "|    policy_loss        | -158      |\n",
      "|    reward             | 3.8347445 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 15.8      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 192         |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 10          |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 399         |\n",
      "|    policy_loss        | 142         |\n",
      "|    reward             | -0.42792106 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 11.1        |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 196      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 291      |\n",
      "|    reward             | -8.69314 |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 71.7     |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 191         |\n",
      "|    iterations         | 600         |\n",
      "|    time_elapsed       | 15          |\n",
      "|    total_timesteps    | 3000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41.4       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 599         |\n",
      "|    policy_loss        | 115         |\n",
      "|    reward             | -0.48451066 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 9.75        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 187        |\n",
      "|    iterations         | 700        |\n",
      "|    time_elapsed       | 18         |\n",
      "|    total_timesteps    | 3500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.4      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 699        |\n",
      "|    policy_loss        | 2.78       |\n",
      "|    reward             | -2.3205562 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 0.386      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 194        |\n",
      "|    iterations         | 800        |\n",
      "|    time_elapsed       | 20         |\n",
      "|    total_timesteps    | 4000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.4      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 799        |\n",
      "|    policy_loss        | 2.33       |\n",
      "|    reward             | -3.0805824 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 0.465      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 200        |\n",
      "|    iterations         | 900        |\n",
      "|    time_elapsed       | 22         |\n",
      "|    total_timesteps    | 4500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 899        |\n",
      "|    policy_loss        | 204        |\n",
      "|    reward             | -1.7641853 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 29.8       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 203        |\n",
      "|    iterations         | 1000       |\n",
      "|    time_elapsed       | 24         |\n",
      "|    total_timesteps    | 5000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.5      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 999        |\n",
      "|    policy_loss        | -15.6      |\n",
      "|    reward             | -2.3804846 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 0.311      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 207       |\n",
      "|    iterations         | 1100      |\n",
      "|    time_elapsed       | 26        |\n",
      "|    total_timesteps    | 5500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1099      |\n",
      "|    policy_loss        | -80.5     |\n",
      "|    reward             | -1.708582 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 10.9      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 211        |\n",
      "|    iterations         | 1200       |\n",
      "|    time_elapsed       | 28         |\n",
      "|    total_timesteps    | 6000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.4      |\n",
      "|    explained_variance | -0.0382    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1199       |\n",
      "|    policy_loss        | -58.3      |\n",
      "|    reward             | 0.40569922 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 2.73       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 211        |\n",
      "|    iterations         | 1300       |\n",
      "|    time_elapsed       | 30         |\n",
      "|    total_timesteps    | 6500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1299       |\n",
      "|    policy_loss        | 27.2       |\n",
      "|    reward             | -3.7707815 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 3.76       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 213       |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 32        |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | 29.8      |\n",
      "|    reward             | 1.9682304 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 2.13      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 216       |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 34        |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | 46.2      |\n",
      "|    reward             | 10.161062 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.87      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 219      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 133      |\n",
      "|    reward             | 2.418494 |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 11.5     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 1700      |\n",
      "|    time_elapsed       | 38        |\n",
      "|    total_timesteps    | 8500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.5     |\n",
      "|    explained_variance | 0.141     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1699      |\n",
      "|    policy_loss        | -93.6     |\n",
      "|    reward             | 3.7694008 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 18.2      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 222       |\n",
      "|    iterations         | 1800      |\n",
      "|    time_elapsed       | 40        |\n",
      "|    total_timesteps    | 9000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1799      |\n",
      "|    policy_loss        | -21.9     |\n",
      "|    reward             | 1.7124854 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.665     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 224        |\n",
      "|    iterations         | 1900       |\n",
      "|    time_elapsed       | 42         |\n",
      "|    total_timesteps    | 9500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1899       |\n",
      "|    policy_loss        | 11.1       |\n",
      "|    reward             | 0.19421776 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 1.44       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 225         |\n",
      "|    iterations         | 2000        |\n",
      "|    time_elapsed       | 44          |\n",
      "|    total_timesteps    | 10000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1999        |\n",
      "|    policy_loss        | -67.1       |\n",
      "|    reward             | -0.85047406 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 3.21        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 227       |\n",
      "|    iterations         | 2100      |\n",
      "|    time_elapsed       | 46        |\n",
      "|    total_timesteps    | 10500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.5     |\n",
      "|    explained_variance | 0.0468    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2099      |\n",
      "|    policy_loss        | 73.7      |\n",
      "|    reward             | 1.6703827 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 6.26      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 228        |\n",
      "|    iterations         | 2200       |\n",
      "|    time_elapsed       | 48         |\n",
      "|    total_timesteps    | 11000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2199       |\n",
      "|    policy_loss        | 30.3       |\n",
      "|    reward             | -5.2590303 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 5.29       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 228       |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 50        |\n",
      "|    total_timesteps    | 11500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.5     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | -2.48e+03 |\n",
      "|    reward             | 0.4916175 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 3.67e+03  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 228        |\n",
      "|    iterations         | 2400       |\n",
      "|    time_elapsed       | 52         |\n",
      "|    total_timesteps    | 12000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.5      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2399       |\n",
      "|    policy_loss        | 55.7       |\n",
      "|    reward             | 0.07138527 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 6.47       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 228         |\n",
      "|    iterations         | 2500        |\n",
      "|    time_elapsed       | 54          |\n",
      "|    total_timesteps    | 12500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41.5       |\n",
      "|    explained_variance | -0.729      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2499        |\n",
      "|    policy_loss        | -79.6       |\n",
      "|    reward             | -0.35525322 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 4.11        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 229       |\n",
      "|    iterations         | 2600      |\n",
      "|    time_elapsed       | 56        |\n",
      "|    total_timesteps    | 13000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.5     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2599      |\n",
      "|    policy_loss        | 20.7      |\n",
      "|    reward             | 2.4158444 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.88      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 230        |\n",
      "|    iterations         | 2700       |\n",
      "|    time_elapsed       | 58         |\n",
      "|    total_timesteps    | 13500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.5      |\n",
      "|    explained_variance | 0.0408     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2699       |\n",
      "|    policy_loss        | -21.8      |\n",
      "|    reward             | -3.4083464 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 0.834      |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 231      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 60       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.5    |\n",
      "|    explained_variance | 0.0601   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 452      |\n",
      "|    reward             | 9.306936 |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 146      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 231       |\n",
      "|    iterations         | 2900      |\n",
      "|    time_elapsed       | 62        |\n",
      "|    total_timesteps    | 14500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.5     |\n",
      "|    explained_variance | -2.5      |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2899      |\n",
      "|    policy_loss        | -58.6     |\n",
      "|    reward             | 2.3032017 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 4.63      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 232       |\n",
      "|    iterations         | 3000      |\n",
      "|    time_elapsed       | 64        |\n",
      "|    total_timesteps    | 15000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2999      |\n",
      "|    policy_loss        | 36.2      |\n",
      "|    reward             | 0.9560237 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 1.14      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 233         |\n",
      "|    iterations         | 3100        |\n",
      "|    time_elapsed       | 66          |\n",
      "|    total_timesteps    | 15500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3099        |\n",
      "|    policy_loss        | 65.9        |\n",
      "|    reward             | -0.19981824 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 2.88        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 234       |\n",
      "|    iterations         | 3200      |\n",
      "|    time_elapsed       | 68        |\n",
      "|    total_timesteps    | 16000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.6     |\n",
      "|    explained_variance | 0.05      |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3199      |\n",
      "|    policy_loss        | -65       |\n",
      "|    reward             | -2.725811 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 8.13      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 234         |\n",
      "|    iterations         | 3300        |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 16500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3299        |\n",
      "|    policy_loss        | -176        |\n",
      "|    reward             | -0.47729546 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 27.8        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 235       |\n",
      "|    iterations         | 3400      |\n",
      "|    time_elapsed       | 72        |\n",
      "|    total_timesteps    | 17000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3399      |\n",
      "|    policy_loss        | 50.8      |\n",
      "|    reward             | 4.608425  |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 12.1      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 236         |\n",
      "|    iterations         | 3500        |\n",
      "|    time_elapsed       | 74          |\n",
      "|    total_timesteps    | 17500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41.6       |\n",
      "|    explained_variance | -2.38e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3499        |\n",
      "|    policy_loss        | 100         |\n",
      "|    reward             | 0.014956067 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 7.6         |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 235       |\n",
      "|    iterations         | 3600      |\n",
      "|    time_elapsed       | 76        |\n",
      "|    total_timesteps    | 18000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.7     |\n",
      "|    explained_variance | -1.79e-06 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3599      |\n",
      "|    policy_loss        | -121      |\n",
      "|    reward             | 2.1330433 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 9.18      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 236       |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 78        |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.7     |\n",
      "|    explained_variance | -0.125    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | 172       |\n",
      "|    reward             | 1.2495527 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 20.7      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 236      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 80       |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 85.5     |\n",
      "|    reward             | 0.886247 |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 6.43     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 237       |\n",
      "|    iterations         | 3900      |\n",
      "|    time_elapsed       | 82        |\n",
      "|    total_timesteps    | 19500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3899      |\n",
      "|    policy_loss        | -187      |\n",
      "|    reward             | 1.3876593 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 25.3      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 237      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 84       |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.5    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | -175     |\n",
      "|    reward             | 6.295396 |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 24.8     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 238        |\n",
      "|    iterations         | 4100       |\n",
      "|    time_elapsed       | 86         |\n",
      "|    total_timesteps    | 20500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4099       |\n",
      "|    policy_loss        | -27        |\n",
      "|    reward             | 0.42482704 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 1.73       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 238       |\n",
      "|    iterations         | 4200      |\n",
      "|    time_elapsed       | 87        |\n",
      "|    total_timesteps    | 21000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.7     |\n",
      "|    explained_variance | 0.0288    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4199      |\n",
      "|    policy_loss        | -133      |\n",
      "|    reward             | 0.2702018 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 15.8      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 239      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 89       |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.7    |\n",
      "|    explained_variance | 0.0611   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | -24.9    |\n",
      "|    reward             | 4.367522 |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.33     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 239        |\n",
      "|    iterations         | 4400       |\n",
      "|    time_elapsed       | 91         |\n",
      "|    total_timesteps    | 22000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4399       |\n",
      "|    policy_loss        | 9.79       |\n",
      "|    reward             | 0.95509887 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 3.86       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 239         |\n",
      "|    iterations         | 4500        |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 22500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4499        |\n",
      "|    policy_loss        | 247         |\n",
      "|    reward             | -0.28532243 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 44.4        |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 240      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 95       |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.7    |\n",
      "|    explained_variance | 4.53e-06 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | 129      |\n",
      "|    reward             | 4.759097 |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 11.9     |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 240         |\n",
      "|    iterations         | 4700        |\n",
      "|    time_elapsed       | 97          |\n",
      "|    total_timesteps    | 23500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41.8       |\n",
      "|    explained_variance | 5.36e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4699        |\n",
      "|    policy_loss        | -84.7       |\n",
      "|    reward             | -0.21156447 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 6.51        |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 240      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 99       |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | -59.3    |\n",
      "|    reward             | -0.72911 |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.67     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 240        |\n",
      "|    iterations         | 4900       |\n",
      "|    time_elapsed       | 101        |\n",
      "|    total_timesteps    | 24500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.8      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4899       |\n",
      "|    policy_loss        | -41.7      |\n",
      "|    reward             | 0.51427615 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 1.37       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 241         |\n",
      "|    iterations         | 5000        |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 25000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41.8       |\n",
      "|    explained_variance | 0.126       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4999        |\n",
      "|    policy_loss        | 54.6        |\n",
      "|    reward             | -0.16531105 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 3.09        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 241        |\n",
      "|    iterations         | 5100       |\n",
      "|    time_elapsed       | 105        |\n",
      "|    total_timesteps    | 25500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.8      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5099       |\n",
      "|    policy_loss        | 57.8       |\n",
      "|    reward             | -0.6549667 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 5.74       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 107      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.8    |\n",
      "|    explained_variance | -0.00348 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | -360     |\n",
      "|    reward             | 4.945475 |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 79.2     |\n",
      "------------------------------------\n",
      "day: 2892, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3376762.88\n",
      "total_reward: 2376762.88\n",
      "total_cost: 22103.43\n",
      "total_trades: 51642\n",
      "Sharpe: 0.688\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 241       |\n",
      "|    iterations         | 5300      |\n",
      "|    time_elapsed       | 109       |\n",
      "|    total_timesteps    | 26500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5299      |\n",
      "|    policy_loss        | -10.5     |\n",
      "|    reward             | 0.3474622 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.107     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 242         |\n",
      "|    iterations         | 5400        |\n",
      "|    time_elapsed       | 111         |\n",
      "|    total_timesteps    | 27000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5399        |\n",
      "|    policy_loss        | 59.7        |\n",
      "|    reward             | -0.13626283 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 7.78        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 242       |\n",
      "|    iterations         | 5500      |\n",
      "|    time_elapsed       | 113       |\n",
      "|    total_timesteps    | 27500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.8     |\n",
      "|    explained_variance | 0.125     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5499      |\n",
      "|    policy_loss        | -6.52     |\n",
      "|    reward             | 2.0305579 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 8.22      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 242        |\n",
      "|    iterations         | 5600       |\n",
      "|    time_elapsed       | 115        |\n",
      "|    total_timesteps    | 28000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.9      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5599       |\n",
      "|    policy_loss        | -72.3      |\n",
      "|    reward             | -0.4374273 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 4.22       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 117      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | -31.5    |\n",
      "|    reward             | 0.543871 |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.36     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 119      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.9    |\n",
      "|    explained_variance | -0.016   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | -13.4    |\n",
      "|    reward             | 2.17365  |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.9      |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 242         |\n",
      "|    iterations         | 5900        |\n",
      "|    time_elapsed       | 121         |\n",
      "|    total_timesteps    | 29500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41.9       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5899        |\n",
      "|    policy_loss        | 2.67        |\n",
      "|    reward             | -0.06545198 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 0.131       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 242         |\n",
      "|    iterations         | 6000        |\n",
      "|    time_elapsed       | 123         |\n",
      "|    total_timesteps    | 30000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5999        |\n",
      "|    policy_loss        | 77.3        |\n",
      "|    reward             | -0.36863765 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 4.19        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 243        |\n",
      "|    iterations         | 6100       |\n",
      "|    time_elapsed       | 125        |\n",
      "|    total_timesteps    | 30500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42        |\n",
      "|    explained_variance | 0.269      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6099       |\n",
      "|    policy_loss        | -5.52      |\n",
      "|    reward             | -2.0602355 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 1.78       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 243        |\n",
      "|    iterations         | 6200       |\n",
      "|    time_elapsed       | 127        |\n",
      "|    total_timesteps    | 31000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42        |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6199       |\n",
      "|    policy_loss        | -16.4      |\n",
      "|    reward             | -1.4138739 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 1.87       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 243       |\n",
      "|    iterations         | 6300      |\n",
      "|    time_elapsed       | 129       |\n",
      "|    total_timesteps    | 31500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6299      |\n",
      "|    policy_loss        | -21.3     |\n",
      "|    reward             | 1.5284014 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 1.74      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 243       |\n",
      "|    iterations         | 6400      |\n",
      "|    time_elapsed       | 131       |\n",
      "|    total_timesteps    | 32000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6399      |\n",
      "|    policy_loss        | 119       |\n",
      "|    reward             | 1.1997501 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 8.77      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 244        |\n",
      "|    iterations         | 6500       |\n",
      "|    time_elapsed       | 133        |\n",
      "|    total_timesteps    | 32500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6499       |\n",
      "|    policy_loss        | -7.65      |\n",
      "|    reward             | -2.4580638 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 2.83       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 244        |\n",
      "|    iterations         | 6600       |\n",
      "|    time_elapsed       | 135        |\n",
      "|    total_timesteps    | 33000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6599       |\n",
      "|    policy_loss        | -96.6      |\n",
      "|    reward             | 0.17706966 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 8.55       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 244       |\n",
      "|    iterations         | 6700      |\n",
      "|    time_elapsed       | 136       |\n",
      "|    total_timesteps    | 33500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6699      |\n",
      "|    policy_loss        | -554      |\n",
      "|    reward             | -4.850846 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 232       |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 244         |\n",
      "|    iterations         | 6800        |\n",
      "|    time_elapsed       | 138         |\n",
      "|    total_timesteps    | 34000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.1       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6799        |\n",
      "|    policy_loss        | -82.7       |\n",
      "|    reward             | -0.32500663 |\n",
      "|    std                | 1.04        |\n",
      "|    value_loss         | 5.91        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 244       |\n",
      "|    iterations         | 6900      |\n",
      "|    time_elapsed       | 140       |\n",
      "|    total_timesteps    | 34500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6899      |\n",
      "|    policy_loss        | -191      |\n",
      "|    reward             | 0.2017239 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 28.5      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 244         |\n",
      "|    iterations         | 7000        |\n",
      "|    time_elapsed       | 142         |\n",
      "|    total_timesteps    | 35000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6999        |\n",
      "|    policy_loss        | 32.3        |\n",
      "|    reward             | 0.051370304 |\n",
      "|    std                | 1.04        |\n",
      "|    value_loss         | 0.784       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 244        |\n",
      "|    iterations         | 7100       |\n",
      "|    time_elapsed       | 144        |\n",
      "|    total_timesteps    | 35500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7099       |\n",
      "|    policy_loss        | 33.2       |\n",
      "|    reward             | 0.28801063 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 1.03       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 245       |\n",
      "|    iterations         | 7200      |\n",
      "|    time_elapsed       | 146       |\n",
      "|    total_timesteps    | 36000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.2     |\n",
      "|    explained_variance | -0.176    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7199      |\n",
      "|    policy_loss        | -220      |\n",
      "|    reward             | 1.0068564 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 29.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 245       |\n",
      "|    iterations         | 7300      |\n",
      "|    time_elapsed       | 148       |\n",
      "|    total_timesteps    | 36500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7299      |\n",
      "|    policy_loss        | 142       |\n",
      "|    reward             | 0.7472625 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 19.3      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 245        |\n",
      "|    iterations         | 7400       |\n",
      "|    time_elapsed       | 150        |\n",
      "|    total_timesteps    | 37000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.3      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7399       |\n",
      "|    policy_loss        | -111       |\n",
      "|    reward             | -2.9238696 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 11         |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 245        |\n",
      "|    iterations         | 7500       |\n",
      "|    time_elapsed       | 152        |\n",
      "|    total_timesteps    | 37500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7499       |\n",
      "|    policy_loss        | 270        |\n",
      "|    reward             | -1.3443186 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 41.1       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 245        |\n",
      "|    iterations         | 7600       |\n",
      "|    time_elapsed       | 154        |\n",
      "|    total_timesteps    | 38000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7599       |\n",
      "|    policy_loss        | 19.5       |\n",
      "|    reward             | 0.96825063 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 0.756      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 245       |\n",
      "|    iterations         | 7700      |\n",
      "|    time_elapsed       | 156       |\n",
      "|    total_timesteps    | 38500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7699      |\n",
      "|    policy_loss        | -38.4     |\n",
      "|    reward             | 1.4141306 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 1.17      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 245      |\n",
      "|    iterations         | 7800     |\n",
      "|    time_elapsed       | 158      |\n",
      "|    total_timesteps    | 39000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | -40.7    |\n",
      "|    reward             | -3.08753 |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 1.28     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 246       |\n",
      "|    iterations         | 7900      |\n",
      "|    time_elapsed       | 160       |\n",
      "|    total_timesteps    | 39500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7899      |\n",
      "|    policy_loss        | 259       |\n",
      "|    reward             | 2.1145034 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 45        |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 246         |\n",
      "|    iterations         | 8000        |\n",
      "|    time_elapsed       | 162         |\n",
      "|    total_timesteps    | 40000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.5       |\n",
      "|    explained_variance | -0.116      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7999        |\n",
      "|    policy_loss        | -130        |\n",
      "|    reward             | -0.52134746 |\n",
      "|    std                | 1.05        |\n",
      "|    value_loss         | 11.8        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 246       |\n",
      "|    iterations         | 8100      |\n",
      "|    time_elapsed       | 164       |\n",
      "|    total_timesteps    | 40500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8099      |\n",
      "|    policy_loss        | -133      |\n",
      "|    reward             | 5.1719775 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 14.9      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 246        |\n",
      "|    iterations         | 8200       |\n",
      "|    time_elapsed       | 166        |\n",
      "|    total_timesteps    | 41000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8199       |\n",
      "|    policy_loss        | -67.5      |\n",
      "|    reward             | -0.9504452 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 3.37       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 246         |\n",
      "|    iterations         | 8300        |\n",
      "|    time_elapsed       | 168         |\n",
      "|    total_timesteps    | 41500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.4       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8299        |\n",
      "|    policy_loss        | 20          |\n",
      "|    reward             | -0.55885357 |\n",
      "|    std                | 1.05        |\n",
      "|    value_loss         | 0.547       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 246        |\n",
      "|    iterations         | 8400       |\n",
      "|    time_elapsed       | 170        |\n",
      "|    total_timesteps    | 42000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8399       |\n",
      "|    policy_loss        | 141        |\n",
      "|    reward             | -2.4237494 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 13.4       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 246       |\n",
      "|    iterations         | 8500      |\n",
      "|    time_elapsed       | 172       |\n",
      "|    total_timesteps    | 42500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8499      |\n",
      "|    policy_loss        | 118       |\n",
      "|    reward             | 1.6264211 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 7.92      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 246       |\n",
      "|    iterations         | 8600      |\n",
      "|    time_elapsed       | 174       |\n",
      "|    total_timesteps    | 43000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.4     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8599      |\n",
      "|    policy_loss        | 57.3      |\n",
      "|    reward             | -7.324854 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 8.51      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 246       |\n",
      "|    iterations         | 8700      |\n",
      "|    time_elapsed       | 176       |\n",
      "|    total_timesteps    | 43500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.4     |\n",
      "|    explained_variance | -0.0255   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8699      |\n",
      "|    policy_loss        | 104       |\n",
      "|    reward             | 3.3321626 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 7.26      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 246       |\n",
      "|    iterations         | 8800      |\n",
      "|    time_elapsed       | 178       |\n",
      "|    total_timesteps    | 44000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.4     |\n",
      "|    explained_variance | -3.43e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8799      |\n",
      "|    policy_loss        | -84       |\n",
      "|    reward             | 1.1198848 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 3.76      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 8900     |\n",
      "|    time_elapsed       | 180      |\n",
      "|    total_timesteps    | 44500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0.0167   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8899     |\n",
      "|    policy_loss        | 118      |\n",
      "|    reward             | 2.254068 |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 10       |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 246        |\n",
      "|    iterations         | 9000       |\n",
      "|    time_elapsed       | 182        |\n",
      "|    total_timesteps    | 45000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.4      |\n",
      "|    explained_variance | -0.0337    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8999       |\n",
      "|    policy_loss        | 21         |\n",
      "|    reward             | -2.0408742 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 4.99       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 246       |\n",
      "|    iterations         | 9100      |\n",
      "|    time_elapsed       | 184       |\n",
      "|    total_timesteps    | 45500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.5     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9099      |\n",
      "|    policy_loss        | -43       |\n",
      "|    reward             | 0.6748408 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 1.35      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 246       |\n",
      "|    iterations         | 9200      |\n",
      "|    time_elapsed       | 186       |\n",
      "|    total_timesteps    | 46000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9199      |\n",
      "|    policy_loss        | 101       |\n",
      "|    reward             | 1.0730885 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 6.52      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 246        |\n",
      "|    iterations         | 9300       |\n",
      "|    time_elapsed       | 188        |\n",
      "|    total_timesteps    | 46500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9299       |\n",
      "|    policy_loss        | -181       |\n",
      "|    reward             | -0.3472353 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 20.2       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 246        |\n",
      "|    iterations         | 9400       |\n",
      "|    time_elapsed       | 190        |\n",
      "|    total_timesteps    | 47000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.5      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9399       |\n",
      "|    policy_loss        | 116        |\n",
      "|    reward             | -0.6576417 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 9.03       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 247        |\n",
      "|    iterations         | 9500       |\n",
      "|    time_elapsed       | 192        |\n",
      "|    total_timesteps    | 47500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.5      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9499       |\n",
      "|    policy_loss        | 64.3       |\n",
      "|    reward             | 0.95229864 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 4.36       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 247        |\n",
      "|    iterations         | 9600       |\n",
      "|    time_elapsed       | 194        |\n",
      "|    total_timesteps    | 48000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.5      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9599       |\n",
      "|    policy_loss        | -70.2      |\n",
      "|    reward             | -3.8576798 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 2.85       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 247      |\n",
      "|    iterations         | 9700     |\n",
      "|    time_elapsed       | 196      |\n",
      "|    total_timesteps    | 48500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9699     |\n",
      "|    policy_loss        | -95.7    |\n",
      "|    reward             | 2.567111 |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 7.29     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 247      |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 198      |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | -42.7    |\n",
      "|    reward             | 3.235609 |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 26.6     |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 247         |\n",
      "|    iterations         | 9900        |\n",
      "|    time_elapsed       | 200         |\n",
      "|    total_timesteps    | 49500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9899        |\n",
      "|    policy_loss        | 41.8        |\n",
      "|    reward             | -0.35585898 |\n",
      "|    std                | 1.05        |\n",
      "|    value_loss         | 1.47        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 247        |\n",
      "|    iterations         | 10000      |\n",
      "|    time_elapsed       | 201        |\n",
      "|    total_timesteps    | 50000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9999       |\n",
      "|    policy_loss        | -15        |\n",
      "|    reward             | -1.3213593 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 0.542      |\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_a2c = agent.train_model(model=model_a2c, \n",
    "                             tb_log_name='a2c',\n",
    "                             total_timesteps=50000) if if_using_a2c else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MRiOtrywfAo1"
   },
   "source": [
    "### Agent 2: DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M2YadjfnLwgt",
    "outputId": "2daa7acb-8985-4122-84ca-74537316bef2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.001}\n",
      "Using cuda device\n",
      "Logging to results/ddpg\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "model_ddpg = agent.get_model(\"ddpg\")\n",
    "\n",
    "if if_using_ddpg:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/ddpg'\n",
    "  new_logger_ddpg = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_ddpg.set_logger(new_logger_ddpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tCDa78rqfO_a",
    "outputId": "5ef7cb2f-7665-4266-8fab-2f9534de43cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5879736.97\n",
      "total_reward: 4879736.97\n",
      "total_cost: 5183.20\n",
      "total_trades: 41968\n",
      "Sharpe: 0.878\n",
      "=================================\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 4        |\n",
      "|    fps             | 215      |\n",
      "|    time_elapsed    | 53       |\n",
      "|    total_timesteps | 11572    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 23.1     |\n",
      "|    critic_loss     | 117      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 8679     |\n",
      "|    reward          | 1.796112 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 8        |\n",
      "|    fps             | 208      |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 23144    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 4.22     |\n",
      "|    critic_loss     | 8.69     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 20251    |\n",
      "|    reward          | 1.796112 |\n",
      "---------------------------------\n",
      "day: 2892, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4090886.33\n",
      "total_reward: 3090886.33\n",
      "total_cost: 999.00\n",
      "total_trades: 43380\n",
      "Sharpe: 0.724\n",
      "=================================\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 12       |\n",
      "|    fps             | 204      |\n",
      "|    time_elapsed    | 169      |\n",
      "|    total_timesteps | 34716    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.06    |\n",
      "|    critic_loss     | 5.14     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 31823    |\n",
      "|    reward          | 1.796112 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 16       |\n",
      "|    fps             | 203      |\n",
      "|    time_elapsed    | 227      |\n",
      "|    total_timesteps | 46288    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -5.46    |\n",
      "|    critic_loss     | 3.26     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 43395    |\n",
      "|    reward          | 1.796112 |\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_ddpg = agent.train_model(model=model_ddpg, \n",
    "                             tb_log_name='ddpg',\n",
    "                             total_timesteps=50000) if if_using_ddpg else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_gDkU-j-fCmZ"
   },
   "source": [
    "### Agent 3: PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y5D5PFUhMzSV",
    "outputId": "54d861fd-b7d5-47f1-e0d6-fe8301a6fee3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cuda device\n",
      "Logging to results/ppo\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "PPO_PARAMS = {\n",
    "    \"n_steps\": 2048,\n",
    "    \"ent_coef\": 0.01,\n",
    "    \"learning_rate\": 0.00025,\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS)\n",
    "\n",
    "if if_using_ppo:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/ppo'\n",
    "  new_logger_ppo = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_ppo.set_logger(new_logger_ppo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gt8eIQKYM4G3",
    "outputId": "52802a60-c084-4d89-96cf-b645177f7161"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    fps             | 289        |\n",
      "|    iterations      | 1          |\n",
      "|    time_elapsed    | 7          |\n",
      "|    total_timesteps | 2048       |\n",
      "| train/             |            |\n",
      "|    reward          | 0.87762654 |\n",
      "-----------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020283053 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.2       |\n",
      "|    explained_variance   | -0.00647    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.99        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0231     |\n",
      "|    reward               | 0.3194658   |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 18.6        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3501244.92\n",
      "total_reward: 2501244.92\n",
      "total_cost: 341829.52\n",
      "total_trades: 80414\n",
      "Sharpe: 0.731\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 21          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017204307 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.3       |\n",
      "|    explained_variance   | 0.0149      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.9        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0185     |\n",
      "|    reward               | -1.3461367  |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 92.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015335784 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.3       |\n",
      "|    explained_variance   | -0.0206     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.3        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    reward               | 3.3686736   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 49.6        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 288       |\n",
      "|    iterations           | 5         |\n",
      "|    time_elapsed         | 35        |\n",
      "|    total_timesteps      | 10240     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0228284 |\n",
      "|    clip_fraction        | 0.2       |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.3     |\n",
      "|    explained_variance   | -0.00329  |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 7.08      |\n",
      "|    n_updates            | 40        |\n",
      "|    policy_gradient_loss | -0.0172   |\n",
      "|    reward               | 3.2354167 |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 17.1      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 42          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018911459 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.4       |\n",
      "|    explained_variance   | -0.0015     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.1        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    reward               | 1.7723184   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 49.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 288        |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 49         |\n",
      "|    total_timesteps      | 14336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01951073 |\n",
      "|    clip_fraction        | 0.191      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -41.4      |\n",
      "|    explained_variance   | 0.00439    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 27.3       |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.0149    |\n",
      "|    reward               | 1.031995   |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 66         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 56          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019246884 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.5       |\n",
      "|    explained_variance   | -0.0113     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.45        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    reward               | 0.3545329   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 20.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 288        |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 63         |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01674665 |\n",
      "|    clip_fraction        | 0.191      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -41.5      |\n",
      "|    explained_variance   | -0.000618  |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 31.8       |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.0192    |\n",
      "|    reward               | 0.8694688  |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 35.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 71          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027437657 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.5       |\n",
      "|    explained_variance   | 0.00472     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.8        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    reward               | 0.5345237   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 24.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 78          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019904159 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.6       |\n",
      "|    explained_variance   | 0.0186      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.3        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    reward               | 2.5332363   |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 49.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 85          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01804882  |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.6       |\n",
      "|    explained_variance   | -0.124      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.52        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    reward               | -0.28071454 |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 15.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 287        |\n",
      "|    iterations           | 13         |\n",
      "|    time_elapsed         | 92         |\n",
      "|    total_timesteps      | 26624      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01642077 |\n",
      "|    clip_fraction        | 0.217      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -41.6      |\n",
      "|    explained_variance   | 0.00447    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 29.3       |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.0101    |\n",
      "|    reward               | 0.27773607 |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 49.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 99          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014291599 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.7       |\n",
      "|    explained_variance   | 0.00793     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.3        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    reward               | 0.5954931   |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 58.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 107         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014283054 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.7       |\n",
      "|    explained_variance   | -0.00155    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.27        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0203     |\n",
      "|    reward               | 4.62778     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 21.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 114         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024460556 |\n",
      "|    clip_fraction        | 0.28        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.7       |\n",
      "|    explained_variance   | 0.00647     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.24        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0212     |\n",
      "|    reward               | -0.39212668 |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 34.5        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3279182.10\n",
      "total_reward: 2279182.10\n",
      "total_cost: 319558.13\n",
      "total_trades: 78182\n",
      "Sharpe: 0.687\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 121         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025823416 |\n",
      "|    clip_fraction        | 0.312       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.8       |\n",
      "|    explained_variance   | 0.0101      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0203     |\n",
      "|    reward               | 0.98024595  |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 43.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 128         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.0199745   |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.9       |\n",
      "|    explained_variance   | -0.0196     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.7        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    reward               | -0.50554293 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 66.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 287        |\n",
      "|    iterations           | 19         |\n",
      "|    time_elapsed         | 135        |\n",
      "|    total_timesteps      | 38912      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0260233  |\n",
      "|    clip_fraction        | 0.307      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42        |\n",
      "|    explained_variance   | 0.00917    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.25       |\n",
      "|    n_updates            | 180        |\n",
      "|    policy_gradient_loss | -0.018     |\n",
      "|    reward               | -0.7083784 |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 12.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 142         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.03515938  |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42         |\n",
      "|    explained_variance   | -0.00523    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.4        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    reward               | -0.53809494 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 44.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 150         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025070624 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42         |\n",
      "|    explained_variance   | -0.0358     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26          |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    reward               | -6.362581   |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 49.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 286        |\n",
      "|    iterations           | 22         |\n",
      "|    time_elapsed         | 157        |\n",
      "|    total_timesteps      | 45056      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02644777 |\n",
      "|    clip_fraction        | 0.259      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.1      |\n",
      "|    explained_variance   | -0.0155    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.5       |\n",
      "|    n_updates            | 210        |\n",
      "|    policy_gradient_loss | -0.0168    |\n",
      "|    reward               | 1.620837   |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 26.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 164         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028127516 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.2       |\n",
      "|    explained_variance   | -0.0057     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.6        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    reward               | -0.17584759 |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 45.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 287        |\n",
      "|    iterations           | 24         |\n",
      "|    time_elapsed         | 171        |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02983087 |\n",
      "|    clip_fraction        | 0.27       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.2      |\n",
      "|    explained_variance   | -0.00203   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14.1       |\n",
      "|    n_updates            | 230        |\n",
      "|    policy_gradient_loss | -0.0179    |\n",
      "|    reward               | 4.820556   |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 34.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 178         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01951289  |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.3       |\n",
      "|    explained_variance   | 0.00067     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.4        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    reward               | -0.79622877 |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 55          |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_ppo = agent.train_model(model=model_ppo, \n",
    "                             tb_log_name='ppo',\n",
    "                             total_timesteps=50000) if if_using_ppo else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Zpv4S0-fDBv"
   },
   "source": [
    "### Agent 4: TD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JSAHhV4Xc-bh",
    "outputId": "4a18e366-4c60-4262-cebd-9f291072fdb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n",
      "Using cuda device\n",
      "Logging to results/td3\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "TD3_PARAMS = {\"batch_size\": 100, \n",
    "              \"buffer_size\": 1000000, \n",
    "              \"learning_rate\": 0.001}\n",
    "\n",
    "model_td3 = agent.get_model(\"td3\",model_kwargs = TD3_PARAMS)\n",
    "\n",
    "if if_using_td3:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/td3'\n",
    "  new_logger_td3 = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_td3.set_logger(new_logger_td3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OSRxNYAxdKpU",
    "outputId": "5891ff4e-c36e-4ab7-97e7-75ce12630eeb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 60\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4341360.97\n",
      "total_reward: 3341360.97\n",
      "total_cost: 999.00\n",
      "total_trades: 52056\n",
      "Sharpe: 0.707\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 226       |\n",
      "|    time_elapsed    | 51        |\n",
      "|    total_timesteps | 11572     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 98.1      |\n",
      "|    critic_loss     | 2.94e+03  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 8679      |\n",
      "|    reward          | 3.7166758 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 215       |\n",
      "|    time_elapsed    | 107       |\n",
      "|    total_timesteps | 23144     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 47.7      |\n",
      "|    critic_loss     | 415       |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 20251     |\n",
      "|    reward          | 3.7166758 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 12        |\n",
      "|    fps             | 211       |\n",
      "|    time_elapsed    | 164       |\n",
      "|    total_timesteps | 34716     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 40.6      |\n",
      "|    critic_loss     | 52.9      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 31823     |\n",
      "|    reward          | 3.7166758 |\n",
      "----------------------------------\n",
      "day: 2892, episode: 70\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4341360.97\n",
      "total_reward: 3341360.97\n",
      "total_cost: 999.00\n",
      "total_trades: 52056\n",
      "Sharpe: 0.707\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 16        |\n",
      "|    fps             | 209       |\n",
      "|    time_elapsed    | 220       |\n",
      "|    total_timesteps | 46288     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 37        |\n",
      "|    critic_loss     | 26.9      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 43395     |\n",
      "|    reward          | 3.7166758 |\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_td3 = agent.train_model(model=model_td3, \n",
    "                             tb_log_name='td3',\n",
    "                             total_timesteps=50000) if if_using_td3 else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dr49PotrfG01"
   },
   "source": [
    "### Agent 5: SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xwOhVjqRkCdM",
    "outputId": "bf6bfbf2-251a-4c76-ac72-1730dbc71eac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'buffer_size': 100000, 'learning_rate': 0.0001, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
      "Using cuda device\n",
      "Logging to results/sac\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "SAC_PARAMS = {\n",
    "    \"batch_size\": 128,\n",
    "    \"buffer_size\": 100000,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"learning_starts\": 100,\n",
    "    \"ent_coef\": \"auto_0.1\",\n",
    "}\n",
    "\n",
    "model_sac = agent.get_model(\"sac\",model_kwargs = SAC_PARAMS)\n",
    "\n",
    "if if_using_sac:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/sac'\n",
    "  new_logger_sac = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_sac.set_logger(new_logger_sac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K8RSdKCckJyH",
    "outputId": "313f9f27-3b80-4b00-d2ce-6bc5ea86ca27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 4          |\n",
      "|    fps             | 150        |\n",
      "|    time_elapsed    | 76         |\n",
      "|    total_timesteps | 11572      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 1.07e+03   |\n",
      "|    critic_loss     | 665        |\n",
      "|    ent_coef        | 0.197      |\n",
      "|    ent_coef_loss   | -60.8      |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 11471      |\n",
      "|    reward          | -1.1844194 |\n",
      "-----------------------------------\n",
      "day: 2892, episode: 80\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5158965.75\n",
      "total_reward: 4158965.75\n",
      "total_cost: 79879.62\n",
      "total_trades: 56150\n",
      "Sharpe: 0.678\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 8          |\n",
      "|    fps             | 150        |\n",
      "|    time_elapsed    | 153        |\n",
      "|    total_timesteps | 23144      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 548        |\n",
      "|    critic_loss     | 141        |\n",
      "|    ent_coef        | 0.0625     |\n",
      "|    ent_coef_loss   | -98.7      |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 23043      |\n",
      "|    reward          | 0.21755634 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 12         |\n",
      "|    fps             | 150        |\n",
      "|    time_elapsed    | 231        |\n",
      "|    total_timesteps | 34716      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 273        |\n",
      "|    critic_loss     | 58.2       |\n",
      "|    ent_coef        | 0.0204     |\n",
      "|    ent_coef_loss   | -95.5      |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 34615      |\n",
      "|    reward          | 0.80976653 |\n",
      "-----------------------------------\n",
      "day: 2892, episode: 90\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5291086.88\n",
      "total_reward: 4291086.88\n",
      "total_cost: 3146.59\n",
      "total_trades: 42769\n",
      "Sharpe: 0.787\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 16        |\n",
      "|    fps             | 150       |\n",
      "|    time_elapsed    | 308       |\n",
      "|    total_timesteps | 46288     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 151       |\n",
      "|    critic_loss     | 53        |\n",
      "|    ent_coef        | 0.00702   |\n",
      "|    ent_coef_loss   | -39.7     |\n",
      "|    learning_rate   | 0.0001    |\n",
      "|    n_updates       | 46187     |\n",
      "|    reward          | 1.6492934 |\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_sac = agent.train_model(model=model_sac, \n",
    "                             tb_log_name='sac',\n",
    "                             total_timesteps=50000) if if_using_sac else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2wZgkQXh1jE"
   },
   "source": [
    "## In-sample Performance\n",
    "\n",
    "Assume that the initial capital is $1,000,000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bEv5KGC8h1jE"
   },
   "source": [
    "### Set turbulence threshold\n",
    "Set the turbulence threshold to be greater than the maximum of insample turbulence data. If current turbulence index is greater than the threshold, then we assume that the current market is volatile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "efwBi84ch1jE"
   },
   "outputs": [],
   "source": [
    "data_risk_indicator = processed_full[(processed_full.date<TRAIN_END_DATE) & (processed_full.date>=TRAIN_START_DATE)]\n",
    "insample_risk_indicator = data_risk_indicator.drop_duplicates(subset=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VHZMBpSqh1jG",
    "outputId": "ff203a99-ab49-4970-810a-645f30fab21c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "count    2893.000000\nmean       18.824245\nstd         8.489311\nmin         9.140000\n25%        13.330000\n50%        16.139999\n75%        21.309999\nmax        82.690002\nName: vix, dtype: float64"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_risk_indicator.vix.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BDkszkMloRWT",
    "outputId": "3fae2054-33b6-40da-f057-78da8dda3077"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "57.40400183105453"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_risk_indicator.vix.quantile(0.996)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AL7hs7svnNWT",
    "outputId": "7ff675ad-25b8-4d26-ef32-f58237d20b00"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "count    2893.000000\nmean       34.567958\nstd        43.790839\nmin         0.000000\n25%        14.962792\n50%        24.124157\n75%        39.162462\nmax       652.505535\nName: turbulence, dtype: float64"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_risk_indicator.turbulence.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N78hfHckoqJ9",
    "outputId": "f5e548c1-6891-4209-cbff-0e25b54fc8aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "276.45251865679705"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_risk_indicator.turbulence.quantile(0.996)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U5mmgQF_h1jQ"
   },
   "source": [
    "### Trading (Out-of-sample Performance)\n",
    "\n",
    "We update periodically in order to take full advantage of the data, e.g., retrain quarterly, monthly or weekly. We also tune the parameters along the way, in this notebook we use the in-sample data from 2009-01 to 2020-07 to tune the parameters once, so there is some alpha decay here as the length of trade date extends. \n",
    "\n",
    "Numerous hyperparameters – e.g. the learning rate, the total number of samples to train on – influence the learning process and are usually determined by testing some variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "cIqoV0GSI52v"
   },
   "outputs": [],
   "source": [
    "e_trade_gym = StockTradingEnv(df = trade, turbulence_threshold = 70,risk_indicator_col='vix', **env_kwargs)\n",
    "# env_trade, obs_trade = e_trade_gym.get_sb_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "W_XNgGsBMeVw",
    "outputId": "45a92b16-4907-421b-bf48-8b0ff4bff45b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "         date   tic        open        high         low       close  \\\n0  2020-07-01  AAPL   91.279999   91.839996   90.977501   89.631218   \n0  2020-07-01  AMGN  235.520004  256.230011  232.580002  236.683334   \n0  2020-07-01   AXP   95.250000   96.959999   93.639999   91.078461   \n0  2020-07-01    BA  185.880005  190.610001  180.039993  180.320007   \n0  2020-07-01   CAT  129.380005  129.399994  125.879997  118.455795   \n\n        volume  day      macd     boll_ub     boll_lb     rsi_30      cci_30  \\\n0  110737200.0  2.0  3.005436   92.417426   79.936126  62.807160  107.496733   \n0    6575800.0  2.0  3.583839  229.038886  197.319561  61.279648  271.050749   \n0    3301000.0  2.0 -0.384903  109.215325   86.798782  48.504812  -66.306199   \n0   49036700.0  2.0  5.443193  220.721139  160.932863  50.925771   24.220608   \n0    2807800.0  2.0  1.249468  128.246938  111.290109  52.865421   35.692984   \n\n       dx_30  close_30_sma  close_60_sma        vix  turbulence  \n0  29.730532     83.678529     77.481209  28.620001   53.068034  \n0  46.806139    211.753605    212.811100  28.620001   53.068034  \n0   3.142448     96.180268     89.702837  28.620001   53.068034  \n0  15.932920    176.472335    155.614168  28.620001   53.068034  \n0  14.457404    117.239536    111.578319  28.620001   53.068034  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>tic</th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>volume</th>\n      <th>day</th>\n      <th>macd</th>\n      <th>boll_ub</th>\n      <th>boll_lb</th>\n      <th>rsi_30</th>\n      <th>cci_30</th>\n      <th>dx_30</th>\n      <th>close_30_sma</th>\n      <th>close_60_sma</th>\n      <th>vix</th>\n      <th>turbulence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020-07-01</td>\n      <td>AAPL</td>\n      <td>91.279999</td>\n      <td>91.839996</td>\n      <td>90.977501</td>\n      <td>89.631218</td>\n      <td>110737200.0</td>\n      <td>2.0</td>\n      <td>3.005436</td>\n      <td>92.417426</td>\n      <td>79.936126</td>\n      <td>62.807160</td>\n      <td>107.496733</td>\n      <td>29.730532</td>\n      <td>83.678529</td>\n      <td>77.481209</td>\n      <td>28.620001</td>\n      <td>53.068034</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>2020-07-01</td>\n      <td>AMGN</td>\n      <td>235.520004</td>\n      <td>256.230011</td>\n      <td>232.580002</td>\n      <td>236.683334</td>\n      <td>6575800.0</td>\n      <td>2.0</td>\n      <td>3.583839</td>\n      <td>229.038886</td>\n      <td>197.319561</td>\n      <td>61.279648</td>\n      <td>271.050749</td>\n      <td>46.806139</td>\n      <td>211.753605</td>\n      <td>212.811100</td>\n      <td>28.620001</td>\n      <td>53.068034</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>2020-07-01</td>\n      <td>AXP</td>\n      <td>95.250000</td>\n      <td>96.959999</td>\n      <td>93.639999</td>\n      <td>91.078461</td>\n      <td>3301000.0</td>\n      <td>2.0</td>\n      <td>-0.384903</td>\n      <td>109.215325</td>\n      <td>86.798782</td>\n      <td>48.504812</td>\n      <td>-66.306199</td>\n      <td>3.142448</td>\n      <td>96.180268</td>\n      <td>89.702837</td>\n      <td>28.620001</td>\n      <td>53.068034</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>2020-07-01</td>\n      <td>BA</td>\n      <td>185.880005</td>\n      <td>190.610001</td>\n      <td>180.039993</td>\n      <td>180.320007</td>\n      <td>49036700.0</td>\n      <td>2.0</td>\n      <td>5.443193</td>\n      <td>220.721139</td>\n      <td>160.932863</td>\n      <td>50.925771</td>\n      <td>24.220608</td>\n      <td>15.932920</td>\n      <td>176.472335</td>\n      <td>155.614168</td>\n      <td>28.620001</td>\n      <td>53.068034</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>2020-07-01</td>\n      <td>CAT</td>\n      <td>129.380005</td>\n      <td>129.399994</td>\n      <td>125.879997</td>\n      <td>118.455795</td>\n      <td>2807800.0</td>\n      <td>2.0</td>\n      <td>1.249468</td>\n      <td>128.246938</td>\n      <td>111.290109</td>\n      <td>52.865421</td>\n      <td>35.692984</td>\n      <td>14.457404</td>\n      <td>117.239536</td>\n      <td>111.578319</td>\n      <td>28.620001</td>\n      <td>53.068034</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lbFchno5j3xs",
    "outputId": "946fea4e-15e2-4611-9d14-01364e4ad00a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "trained_moedl = trained_a2c\n",
    "df_account_value_a2c, df_actions_a2c = DRLAgent.DRL_prediction(\n",
    "    model=trained_moedl, \n",
    "    environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JbYljWGjj3pH",
    "outputId": "65145e7d-15ff-4e62-94f9-e5256297d5c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "trained_moedl = trained_ddpg\n",
    "df_account_value_ddpg, df_actions_ddpg = DRLAgent.DRL_prediction(\n",
    "    model=trained_moedl, \n",
    "    environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "74jNP2DBj3hb",
    "outputId": "f20ffd89-2b19-4340-9588-10e64a6b3b8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "trained_moedl = trained_ppo\n",
    "df_account_value_ppo, df_actions_ppo = DRLAgent.DRL_prediction(\n",
    "    model=trained_moedl, \n",
    "    environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S7VyGGJPj3SH",
    "outputId": "a3b915fb-540f-4540-b0eb-c3ce085d59ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "trained_moedl = trained_td3\n",
    "df_account_value_td3, df_actions_td3 = DRLAgent.DRL_prediction(\n",
    "    model=trained_moedl, \n",
    "    environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eLOnL5eYh1jR",
    "outputId": "0fa13ef0-b55f-4ca1-ac2c-e007913016ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "trained_moedl = trained_sac\n",
    "df_account_value_sac, df_actions_sac = DRLAgent.DRL_prediction(\n",
    "    model=trained_moedl, \n",
    "    environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ERxw3KqLkcP4",
    "outputId": "a969404e-b684-40e4-c0d7-278df230131c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(336, 2)"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_account_value_a2c.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GcE-t08w6DaW"
   },
   "source": [
    "<a id='7'></a>\n",
    "# Part 6.5: Mean Variance Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "_b1vKXKgSe4G",
    "outputId": "660f771e-5fd0-4de6-8a63-ff840357ec43"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "         date   tic      close\n0  2009-01-02  AAPL   2.762747\n1  2009-01-02  AMGN  44.219177\n2  2009-01-02   AXP  15.365301\n3  2009-01-02    BA  33.941093\n4  2009-01-02   CAT  31.579334",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>tic</th>\n      <th>close</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2009-01-02</td>\n      <td>AAPL</td>\n      <td>2.762747</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2009-01-02</td>\n      <td>AMGN</td>\n      <td>44.219177</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2009-01-02</td>\n      <td>AXP</td>\n      <td>15.365301</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2009-01-02</td>\n      <td>BA</td>\n      <td>33.941093</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2009-01-02</td>\n      <td>CAT</td>\n      <td>31.579334</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mvo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "fE2YWB0WBDVu"
   },
   "outputs": [],
   "source": [
    "fst = mvo_df\n",
    "fst = fst.iloc[0*29:0*29+29, :]\n",
    "tic = fst['tic'].tolist()\n",
    "\n",
    "mvo = pd.DataFrame()\n",
    "\n",
    "for k in range(len(tic)):\n",
    "  mvo[tic[k]] = 0\n",
    "\n",
    "for i in range(mvo_df.shape[0]//29):\n",
    "  n = mvo_df\n",
    "  n = n.iloc[i*29:i*29+29, :]\n",
    "  date = n['date'][i*29]\n",
    "  mvo.loc[date] = n['close'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9K2xfyh_VcXo",
    "outputId": "a5c14ef9-af8a-47c8-f326-d85b0fb78f66"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "3229"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mvo.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SwEwkHJ1d_6u"
   },
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "kayNWPWn6Kz2"
   },
   "outputs": [],
   "source": [
    "from scipy import optimize \n",
    "from scipy.optimize import linprog\n",
    "\n",
    "#function obtains maximal return portfolio using linear programming\n",
    "\n",
    "def MaximizeReturns(MeanReturns, PortfolioSize):\n",
    "    \n",
    "  #dependencies\n",
    "  \n",
    "    \n",
    "  c = (np.multiply(-1, MeanReturns))\n",
    "  A = np.ones([PortfolioSize,1]).T\n",
    "  b=[1]\n",
    "  res = linprog(c, A_ub = A, b_ub = b, bounds = (0,1), method = 'simplex') \n",
    "    \n",
    "  return res\n",
    "\n",
    "def MinimizeRisk(CovarReturns, PortfolioSize):\n",
    "    \n",
    "  def f(x, CovarReturns):\n",
    "    func = np.matmul(np.matmul(x, CovarReturns), x.T) \n",
    "    return func\n",
    "\n",
    "  def constraintEq(x):\n",
    "    A=np.ones(x.shape)\n",
    "    b=1\n",
    "    constraintVal = np.matmul(A,x.T)-b \n",
    "    return constraintVal\n",
    "    \n",
    "  xinit=np.repeat(0.1, PortfolioSize)\n",
    "  cons = ({'type': 'eq', 'fun':constraintEq})\n",
    "  lb = 0\n",
    "  ub = 1\n",
    "  bnds = tuple([(lb,ub) for x in xinit])\n",
    "\n",
    "  opt = optimize.minimize (f, x0 = xinit, args = (CovarReturns),  bounds = bnds, \\\n",
    "                             constraints = cons, tol = 10**-3)\n",
    "    \n",
    "  return opt\n",
    "\n",
    "def MinimizeRiskConstr(MeanReturns, CovarReturns, PortfolioSize, R):\n",
    "    \n",
    "  def  f(x,CovarReturns):\n",
    "         \n",
    "    func = np.matmul(np.matmul(x,CovarReturns ), x.T)\n",
    "    return func\n",
    "\n",
    "  def constraintEq(x):\n",
    "    AEq=np.ones(x.shape)\n",
    "    bEq=1\n",
    "    EqconstraintVal = np.matmul(AEq,x.T)-bEq \n",
    "    return EqconstraintVal\n",
    "    \n",
    "  def constraintIneq(x, MeanReturns, R):\n",
    "    AIneq = np.array(MeanReturns)\n",
    "    bIneq = R\n",
    "    IneqconstraintVal = np.matmul(AIneq,x.T) - bIneq\n",
    "    return IneqconstraintVal\n",
    "    \n",
    "\n",
    "  xinit=np.repeat(0.1, PortfolioSize)\n",
    "  cons = ({'type': 'eq', 'fun':constraintEq},\n",
    "          {'type':'ineq', 'fun':constraintIneq, 'args':(MeanReturns,R) })\n",
    "  lb = 0\n",
    "  ub = 1\n",
    "  bnds = tuple([(lb,ub) for x in xinit])\n",
    "\n",
    "  opt = optimize.minimize (f, args = (CovarReturns), method ='trust-constr',  \\\n",
    "                x0 = xinit,   bounds = bnds, constraints = cons, tol = 10**-3)\n",
    "    \n",
    "  return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "6KvXkpyE8MFq"
   },
   "outputs": [],
   "source": [
    "def StockReturnsComputing(StockPrice, Rows, Columns): \n",
    "  import numpy as np \n",
    "  StockReturn = np.zeros([Rows-1, Columns]) \n",
    "  for j in range(Columns):        # j: Assets \n",
    "    for i in range(Rows-1):     # i: Daily Prices \n",
    "      StockReturn[i,j]=((StockPrice[i+1, j]-StockPrice[i,j])/StockPrice[i,j])* 100 \n",
    "      \n",
    "  return StockReturn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IeVVbuwveJ_5"
   },
   "source": [
    "### Calculate mean returns and variance-covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q2G1phEm_Ut3",
    "outputId": "88d98b75-449e-49b6-b4bb-3407dd53a7ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 89.63121796, 236.68333435,  91.07846069, ...,  47.76708603,\n         36.77028656, 115.09745789],\n       [ 89.63121796, 239.57788086,  91.349617  , ...,  47.87194061,\n         37.75970459, 114.63587952],\n       [ 92.028862  , 237.73168945,  93.52852631, ...,  48.26511765,\n         38.82107544, 114.32814789],\n       ...,\n       [148.24203491, 200.60629272, 178.0160675 , ...,  49.54628754,\n         45.73178101, 145.86064148],\n       [147.7754364 , 198.58755493, 175.14343262, ...,  49.12624359,\n         44.60528946, 144.66435242],\n       [151.46856689, 199.15470886, 171.77888489, ...,  49.28492737,\n         44.5863533 , 145.56646729]])"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtain optimal portfolio sets that maximize return and minimize risk\n",
    "\n",
    "#Dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#input k-portfolio 1 dataset comprising 15 stocks\n",
    "# StockFileName = './DJIA_Apr112014_Apr112019_kpf1.csv'\n",
    "\n",
    "Rows = 1259  #excluding header\n",
    "Columns = 15  #excluding date\n",
    "portfolioSize = 29 #set portfolio size\n",
    "\n",
    "#read stock prices in a dataframe\n",
    "# df = pd.read_csv(StockFileName,  nrows= Rows)\n",
    "\n",
    "#extract asset labels\n",
    "# assetLabels = df.columns[1:Columns+1].tolist()\n",
    "# print(assetLabels)\n",
    "\n",
    "#extract asset prices\n",
    "# StockData = df.iloc[0:, 1:]\n",
    "StockData = mvo.head(mvo.shape[0]-336)\n",
    "TradeData = mvo.tail(336)\n",
    "# df.head()\n",
    "TradeData.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u6_O6vrn_uD4",
    "outputId": "06b9933d-9217-44a0-f800-43764acdcda2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean returns of assets in k-portfolio 1\n",
      " [0.136 0.068 0.086 0.083 0.066 0.134 0.06  0.035 0.072 0.056 0.103 0.073\n",
      " 0.033 0.076 0.047 0.073 0.042 0.056 0.054 0.056 0.103 0.089 0.041 0.053\n",
      " 0.104 0.11  0.044 0.042 0.042]\n",
      "Variance-Covariance matrix of returns\n",
      " [[3.156 1.066 1.768 1.669 1.722 1.814 1.569 1.302 1.302 1.811 1.303 1.432\n",
      "  1.218 1.674 0.74  1.839 0.719 0.884 1.241 0.823 1.561 1.324 0.752 1.027\n",
      "  1.298 1.466 0.657 1.078 0.631]\n",
      " [1.066 2.571 1.306 1.123 1.193 1.319 1.116 1.053 1.045 1.269 1.068 1.089\n",
      "  0.899 1.218 0.926 1.391 0.682 0.727 1.025 1.156 1.166 0.984 0.798 0.956\n",
      "  1.259 1.111 0.688 1.091 0.682]\n",
      " [1.768 1.306 4.847 2.73  2.6   2.128 1.944 2.141 2.17  3.142 1.932 2.283\n",
      "  1.56  2.012 0.993 3.707 1.094 1.319 1.845 1.236 1.899 1.894 1.041 1.921\n",
      "  1.823 2.314 0.986 1.421 0.707]\n",
      " [1.669 1.123 2.73  4.892 2.363 1.979 1.7   2.115 1.959 2.387 1.773 2.319\n",
      "  1.571 1.797 0.968 2.597 1.144 1.298 1.643 1.071 1.615 1.775 0.91  1.666\n",
      "  1.707 1.784 0.82  1.345 0.647]\n",
      " [1.722 1.193 2.6   2.363 4.019 2.127 1.917 2.059 1.817 2.46  1.577 2.238\n",
      "  1.513 1.929 0.925 2.64  0.947 0.971 1.894 1.089 1.711 1.642 0.865 1.456\n",
      "  1.478 1.687 0.92  1.326 0.697]\n",
      " [1.814 1.319 2.128 1.979 2.127 5.384 1.974 1.549 1.683 2.122 1.624 1.771\n",
      "  1.441 1.939 0.846 2.191 0.837 1.075 1.475 1.041 1.978 1.768 0.784 1.328\n",
      "  1.365 1.912 0.787 1.28  0.666]\n",
      " [1.569 1.116 1.944 1.7   1.917 1.974 3.081 1.483 1.534 1.937 1.367 1.62\n",
      "  1.399 1.843 0.894 2.057 0.794 0.905 1.438 1.014 1.72  1.382 0.865 1.206\n",
      "  1.273 1.488 0.811 1.173 0.753]\n",
      " [1.302 1.053 2.141 2.115 2.059 1.549 1.483 2.842 1.525 2.044 1.428 1.783\n",
      "  1.308 1.533 0.878 2.279 0.938 1.092 1.385 1.078 1.429 1.314 0.831 1.459\n",
      "  1.466 1.48  0.83  1.042 0.567]\n",
      " [1.302 1.045 2.17  1.959 1.817 1.683 1.534 1.525 2.661 1.987 1.454 1.748\n",
      "  1.217 1.475 0.791 2.216 0.896 0.973 1.396 0.949 1.379 1.407 0.859 1.268\n",
      "  1.281 1.454 0.81  1.143 0.667]\n",
      " [1.811 1.269 3.142 2.387 2.46  2.122 1.937 2.044 1.987 4.407 1.789 2.12\n",
      "  1.593 1.982 0.945 3.96  0.956 1.094 1.758 1.157 1.788 1.692 0.905 1.879\n",
      "  1.712 2.    0.945 1.421 0.713]\n",
      " [1.303 1.068 1.932 1.773 1.577 1.624 1.367 1.428 1.454 1.789 2.373 1.51\n",
      "  1.166 1.501 0.756 1.941 0.824 0.998 1.239 0.887 1.366 1.414 0.797 1.299\n",
      "  1.296 1.41  0.764 1.071 0.783]\n",
      " [1.432 1.089 2.283 2.319 2.238 1.771 1.62  1.783 1.748 2.12  1.51  2.516\n",
      "  1.326 1.575 0.889 2.345 0.958 1.022 1.623 1.02  1.489 1.532 0.848 1.377\n",
      "  1.444 1.547 0.81  1.211 0.63 ]\n",
      " [1.218 0.899 1.56  1.571 1.513 1.441 1.399 1.308 1.217 1.593 1.166 1.326\n",
      "  2.052 1.399 0.727 1.749 0.786 0.795 1.154 0.829 1.296 1.12  0.743 1.105\n",
      "  1.088 1.214 0.739 0.998 0.598]\n",
      " [1.674 1.218 2.012 1.797 1.929 1.939 1.843 1.533 1.475 1.982 1.501 1.575\n",
      "  1.399 3.289 0.853 2.112 0.85  0.89  1.412 1.002 1.9   1.352 0.842 1.317\n",
      "  1.334 1.487 0.847 1.165 0.766]\n",
      " [0.74  0.926 0.993 0.968 0.925 0.846 0.894 0.878 0.791 0.945 0.756 0.889\n",
      "  0.727 0.853 1.153 1.027 0.642 0.59  0.848 0.892 0.825 0.748 0.694 0.761\n",
      "  0.929 0.819 0.61  0.806 0.547]\n",
      " [1.839 1.391 3.707 2.597 2.64  2.191 2.057 2.279 2.216 3.96  1.941 2.345\n",
      "  1.749 2.112 1.027 5.271 1.08  1.235 1.892 1.297 1.91  1.85  1.068 2.164\n",
      "  1.85  2.169 1.112 1.555 0.779]\n",
      " [0.719 0.682 1.094 1.144 0.947 0.837 0.794 0.938 0.896 0.956 0.824 0.958\n",
      "  0.786 0.85  0.642 1.08  1.264 0.679 0.804 0.74  0.819 0.845 0.749 0.891\n",
      "  0.849 0.794 0.633 0.719 0.514]\n",
      " [0.884 0.727 1.319 1.298 0.971 1.075 0.905 1.092 0.973 1.094 0.998 1.022\n",
      "  0.795 0.89  0.59  1.235 0.679 1.518 0.816 0.719 0.943 1.027 0.615 1.\n",
      "  0.947 0.994 0.533 0.673 0.504]\n",
      " [1.241 1.025 1.845 1.643 1.894 1.475 1.438 1.385 1.396 1.758 1.239 1.623\n",
      "  1.154 1.412 0.848 1.892 0.804 0.816 2.028 0.9   1.265 1.243 0.787 1.194\n",
      "  1.193 1.282 0.752 1.099 0.622]\n",
      " [0.823 1.156 1.236 1.071 1.089 1.041 1.014 1.078 0.949 1.157 0.887 1.02\n",
      "  0.829 1.002 0.892 1.297 0.74  0.719 0.9   2.007 0.952 0.849 0.732 1.008\n",
      "  1.15  0.933 0.722 0.897 0.614]\n",
      " [1.561 1.166 1.899 1.615 1.711 1.978 1.72  1.429 1.379 1.788 1.366 1.489\n",
      "  1.296 1.9   0.825 1.91  0.819 0.943 1.265 0.952 2.759 1.308 0.832 1.214\n",
      "  1.285 1.493 0.793 1.113 0.705]\n",
      " [1.324 0.984 1.894 1.775 1.642 1.768 1.382 1.314 1.407 1.692 1.414 1.532\n",
      "  1.12  1.352 0.748 1.85  0.845 1.027 1.243 0.849 1.308 2.864 0.751 1.153\n",
      "  1.26  1.411 0.71  1.046 0.651]\n",
      " [0.752 0.798 1.041 0.91  0.865 0.784 0.865 0.831 0.859 0.905 0.797 0.848\n",
      "  0.743 0.842 0.694 1.068 0.749 0.615 0.787 0.732 0.832 0.751 1.289 0.806\n",
      "  0.766 0.763 0.663 0.797 0.645]\n",
      " [1.027 0.956 1.921 1.666 1.456 1.328 1.206 1.459 1.268 1.879 1.299 1.377\n",
      "  1.105 1.317 0.761 2.164 0.891 1.    1.194 1.008 1.214 1.153 0.806 2.27\n",
      "  1.259 1.294 0.812 0.986 0.676]\n",
      " [1.298 1.259 1.823 1.707 1.478 1.365 1.273 1.466 1.281 1.712 1.296 1.444\n",
      "  1.088 1.334 0.929 1.85  0.849 0.947 1.193 1.15  1.285 1.26  0.766 1.259\n",
      "  3.352 1.267 0.697 1.137 0.685]\n",
      " [1.466 1.111 2.314 1.784 1.687 1.912 1.488 1.48  1.454 2.    1.41  1.547\n",
      "  1.214 1.487 0.819 2.169 0.794 0.994 1.282 0.933 1.493 1.411 0.763 1.294\n",
      "  1.267 2.982 0.709 1.007 0.656]\n",
      " [0.657 0.688 0.986 0.82  0.92  0.787 0.811 0.83  0.81  0.945 0.764 0.81\n",
      "  0.739 0.847 0.61  1.112 0.633 0.533 0.752 0.722 0.793 0.71  0.663 0.812\n",
      "  0.697 0.709 1.371 0.697 0.561]\n",
      " [1.078 1.091 1.421 1.345 1.326 1.28  1.173 1.042 1.143 1.421 1.071 1.211\n",
      "  0.998 1.165 0.806 1.555 0.719 0.673 1.099 0.897 1.113 1.046 0.797 0.986\n",
      "  1.137 1.007 0.697 3.073 0.759]\n",
      " [0.631 0.682 0.707 0.647 0.697 0.666 0.753 0.567 0.667 0.713 0.783 0.63\n",
      "  0.598 0.766 0.547 0.779 0.514 0.504 0.622 0.614 0.705 0.651 0.645 0.676\n",
      "  0.685 0.656 0.561 0.759 1.452]]\n"
     ]
    }
   ],
   "source": [
    "#compute asset returns\n",
    "arStockPrices = np.asarray(StockData)\n",
    "[Rows, Cols]=arStockPrices.shape\n",
    "arReturns = StockReturnsComputing(arStockPrices, Rows, Cols)\n",
    "\n",
    "\n",
    "#compute mean returns and variance covariance matrix of returns\n",
    "meanReturns = np.mean(arReturns, axis = 0)\n",
    "covReturns = np.cov(arReturns, rowvar=False)\n",
    " \n",
    "#set precision for printing results\n",
    "np.set_printoptions(precision=3, suppress = True)\n",
    "\n",
    "#display mean returns and variance-covariance matrix of returns\n",
    "print('Mean returns of assets in k-portfolio 1\\n', meanReturns)\n",
    "print('Variance-Covariance matrix of returns\\n', covReturns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1btTONEdCU4",
    "outputId": "13830f03-0872-4991-94c4-e9d1d2e4cd4c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([424250.,      0.,      0.,      0.,      0., 108650.,      0.,\n            0.,      0.,      0., 181450.,      0.,      0.,      0.,\n            0.,      0.,      0.,      0.,      0.,      0.,  16960.,\n            0.,      0.,      0., 133540., 135150.,      0.,      0.,\n            0.])"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "\n",
    "ef_mean = EfficientFrontier(meanReturns, covReturns, weight_bounds=(0, 0.5))\n",
    "raw_weights_mean = ef_mean.max_sharpe()\n",
    "cleaned_weights_mean = ef_mean.clean_weights()\n",
    "mvo_weights = np.array([1000000 * cleaned_weights_mean[i] for i in range(29)])\n",
    "mvo_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "id": "N6tTAjAvgFtO",
    "outputId": "58b6be0e-cd87-4965-fdf6-5b66b1fd1221"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                 AAPL        AMGN        AXP          BA         CAT  \\\n2020-06-30  89.801056  218.815201  91.775711  183.300003  118.869255   \n\n                   CRM       CSCO        CVX         DIS          GS  ...  \\\n2020-06-30  187.330002  42.848259  79.505142  111.510002  187.060181  ...   \n\n                  MRK        MSFT        NKE          PG         TRV  \\\n2020-06-30  67.950203  198.941757  95.878029  111.771378  107.692009   \n\n                  UNH           V         VZ        WBA         WMT  \n2020-06-30  284.97876  189.975403  48.169003  38.128487  115.184013  \n\n[1 rows x 29 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AAPL</th>\n      <th>AMGN</th>\n      <th>AXP</th>\n      <th>BA</th>\n      <th>CAT</th>\n      <th>CRM</th>\n      <th>CSCO</th>\n      <th>CVX</th>\n      <th>DIS</th>\n      <th>GS</th>\n      <th>...</th>\n      <th>MRK</th>\n      <th>MSFT</th>\n      <th>NKE</th>\n      <th>PG</th>\n      <th>TRV</th>\n      <th>UNH</th>\n      <th>V</th>\n      <th>VZ</th>\n      <th>WBA</th>\n      <th>WMT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2020-06-30</th>\n      <td>89.801056</td>\n      <td>218.815201</td>\n      <td>91.775711</td>\n      <td>183.300003</td>\n      <td>118.869255</td>\n      <td>187.330002</td>\n      <td>42.848259</td>\n      <td>79.505142</td>\n      <td>111.510002</td>\n      <td>187.060181</td>\n      <td>...</td>\n      <td>67.950203</td>\n      <td>198.941757</td>\n      <td>95.878029</td>\n      <td>111.771378</td>\n      <td>107.692009</td>\n      <td>284.97876</td>\n      <td>189.975403</td>\n      <td>48.169003</td>\n      <td>38.128487</td>\n      <td>115.184013</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 29 columns</p>\n</div>"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StockData.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F38NJRJJgOmj",
    "outputId": "edae2b4d-44a1-47fc-907e-de546c471875"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([4724.332,    0.   ,    0.   ,    0.   ,    0.   ,  579.993,\n          0.   ,    0.   ,    0.   ,    0.   ,  766.21 ,    0.   ,\n          0.   ,    0.   ,    0.   ,    0.   ,    0.   ,    0.   ,\n          0.   ,    0.   ,   85.251,    0.   ,    0.   ,    0.   ,\n        468.596,  711.408,    0.   ,    0.   ,    0.   ])"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LastPrice = np.array([1/p for p in StockData.tail(1).to_numpy()[0]])\n",
    "Initial_Portfolio = np.multiply(mvo_weights, LastPrice)\n",
    "Initial_Portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "ZAd1iXqZhQ6X",
    "outputId": "1c802633-fc86-415b-ed56-47330c310eb1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                Mean Var\n2020-07-01  1.001918e+06\n2020-07-02  1.004235e+06\n2020-07-06  1.023225e+06\n2020-07-07  1.014021e+06\n2020-07-08  1.029461e+06\n...                  ...\n2021-10-22  1.535667e+06\n2021-10-25  1.542078e+06\n2021-10-26  1.545514e+06\n2021-10-27  1.534916e+06\n2021-10-28  1.550495e+06\n\n[336 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Mean Var</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2020-07-01</th>\n      <td>1.001918e+06</td>\n    </tr>\n    <tr>\n      <th>2020-07-02</th>\n      <td>1.004235e+06</td>\n    </tr>\n    <tr>\n      <th>2020-07-06</th>\n      <td>1.023225e+06</td>\n    </tr>\n    <tr>\n      <th>2020-07-07</th>\n      <td>1.014021e+06</td>\n    </tr>\n    <tr>\n      <th>2020-07-08</th>\n      <td>1.029461e+06</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2021-10-22</th>\n      <td>1.535667e+06</td>\n    </tr>\n    <tr>\n      <th>2021-10-25</th>\n      <td>1.542078e+06</td>\n    </tr>\n    <tr>\n      <th>2021-10-26</th>\n      <td>1.545514e+06</td>\n    </tr>\n    <tr>\n      <th>2021-10-27</th>\n      <td>1.534916e+06</td>\n    </tr>\n    <tr>\n      <th>2021-10-28</th>\n      <td>1.550495e+06</td>\n    </tr>\n  </tbody>\n</table>\n<p>336 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Portfolio_Assets = TradeData @ Initial_Portfolio\n",
    "MVO_result = pd.DataFrame(Portfolio_Assets, columns=[\"Mean Var\"])\n",
    "MVO_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6vvNSC6h1jZ"
   },
   "source": [
    "<a id='6'></a>\n",
    "# Part 7: Backtesting Results\n",
    "Backtesting plays a key role in evaluating the performance of a trading strategy. Automated backtesting tool is preferred because it reduces the human error. We usually use the Quantopian pyfolio package to backtest our trading strategies. It is easy to use and consists of various individual plots that provide a comprehensive image of the performance of a trading strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "KeDeGAc9VrEg"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_121995/3589122252.py:9: FutureWarning: Passing 'suffixes' which cause duplicate columns {'account_value_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  result = pd.merge(result, df_result_ppo, left_index=True, right_index=True)\n"
     ]
    }
   ],
   "source": [
    "df_result_a2c = df_account_value_a2c.set_index(df_account_value_a2c.columns[0])\n",
    "df_result_ddpg = df_account_value_ddpg.set_index(df_account_value_ddpg.columns[0])\n",
    "df_result_td3 = df_account_value_td3.set_index(df_account_value_td3.columns[0])\n",
    "df_result_ppo = df_account_value_ppo.set_index(df_account_value_ppo.columns[0])\n",
    "df_result_sac = df_account_value_sac.set_index(df_account_value_sac.columns[0])\n",
    "\n",
    "result = pd.merge(df_result_a2c, df_result_ddpg, left_index=True, right_index=True)\n",
    "result = pd.merge(result, df_result_td3, left_index=True, right_index=True)\n",
    "result = pd.merge(result, df_result_ppo, left_index=True, right_index=True)\n",
    "result = pd.merge(result, df_result_sac, left_index=True, right_index=True)\n",
    "result = pd.merge(result, MVO_result, left_index=True, right_index=True)\n",
    "result.columns = ['a2c', 'ddpg', 'td3', 'ppo', 'sac', 'mean var']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "6xRfrqK4RVfq",
    "outputId": "868e3da5-3df9-4d54-b181-f630093210f2"
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (15,5)\n",
    "plt.figure();\n",
    "result.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "HMNR5nHjh1iz",
    "uijiWgkuh1jB",
    "MRiOtrywfAo1",
    "_gDkU-j-fCmZ",
    "3Zpv4S0-fDBv"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5 (default, Sep  4 2020, 02:22:02) \n[Clang 10.0.0 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "54cefccbf0f07c9750f12aa115c023dfa5ed4acecf9e7ad3bc9391869be60d0c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
