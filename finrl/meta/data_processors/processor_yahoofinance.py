"""
FinRL Yahoo Finance æ•°æ®å¤„ç†å™¨

è¿™æ˜¯ä¸“é—¨ç”¨äºŽä»ŽYahoo Finance APIèŽ·å–å’Œå¤„ç†è‚¡ç¥¨æ•°æ®çš„æ¨¡å—ã€‚
Yahoo Financeæ˜¯å…¨çƒæœ€æµè¡Œçš„å…è´¹é‡‘èžæ•°æ®æºä¹‹ä¸€ï¼Œæä¾›å®žæ—¶å’ŒåŽ†å²
è‚¡ç¥¨ä»·æ ¼ã€è´¢åŠ¡æ•°æ®å’Œå¸‚åœºç»Ÿè®¡ä¿¡æ¯ã€‚

æ•°æ®å¤„ç†åŠŸèƒ½ï¼š
1. è‚¡ç¥¨ä»·æ ¼æ•°æ®ä¸‹è½½ï¼šæ”¯æŒå¤šç§æ—¶é—´é—´éš”ï¼ˆ1åˆ†é’Ÿåˆ°1æœˆï¼‰
2. æ•°æ®æ¸…æ´—å’Œæ ‡å‡†åŒ–ï¼šå¤„ç†ç¼ºå¤±å€¼ã€å¼‚å¸¸å€¼å’Œæ ¼å¼ç»Ÿä¸€
3. æŠ€æœ¯æŒ‡æ ‡è®¡ç®—ï¼šé›†æˆstockstatsåº“è®¡ç®—å„ç§æŠ€æœ¯æŒ‡æ ‡
4. å¸‚åœºé£Žé™©æŒ‡æ ‡ï¼šè®¡ç®—VIXææ…ŒæŒ‡æ•°å’Œå¸‚åœºæ³¢åŠ¨åº¦
5. æ•°æ®æ ¼å¼è½¬æ¢ï¼šè½¬æ¢ä¸ºæ·±åº¦å­¦ä¹ æ¨¡åž‹æ‰€éœ€çš„æ•°ç»„æ ¼å¼

æ”¯æŒçš„æ•°æ®ç±»åž‹ï¼š
- OHLCVæ•°æ®ï¼šå¼€ç›˜ä»·ã€æœ€é«˜ä»·ã€æœ€ä½Žä»·ã€æ”¶ç›˜ä»·ã€æˆäº¤é‡
- æŠ€æœ¯æŒ‡æ ‡ï¼šMACDã€RSIã€å¸ƒæž—å¸¦ã€ç§»åŠ¨å¹³å‡çº¿ç­‰
- å¸‚åœºæŒ‡æ ‡ï¼šVIXææ…ŒæŒ‡æ•°ã€å¸‚åœºæ³¢åŠ¨åº¦

é‡‘èžæ•°æ®ç‰¹ç‚¹ï¼š
- æ—¶é—´åºåˆ—æ€§ï¼šæ•°æ®æŒ‰æ—¶é—´é¡ºåºæŽ’åˆ—ï¼Œå…·æœ‰æ—¶é—´ä¾èµ–æ€§
- å¤šç»´æ€§ï¼šåŒæ—¶åŒ…å«ä»·æ ¼ã€æˆäº¤é‡ã€æŠ€æœ¯æŒ‡æ ‡ç­‰å¤šä¸ªç»´åº¦
- å™ªå£°æ€§ï¼šå¸‚åœºæ•°æ®åŒ…å«å¤§é‡å™ªå£°ï¼Œéœ€è¦é€‚å½“çš„é¢„å¤„ç†
- éžå¹³ç¨³æ€§ï¼šé‡‘èžæ—¶é—´åºåˆ—é€šå¸¸æ˜¯éžå¹³ç¨³çš„

å‚è€ƒæ¥æºï¼šhttps://github.com/AI4Finance-LLC/FinRL
ä½œè€…ï¼šAI4Finance Foundation
"""

from __future__ import annotations

import datetime
import time
from datetime import date
from datetime import timedelta
from sqlite3 import Timestamp
from typing import Any
from typing import Dict
from typing import List
from typing import Optional
from typing import Type
from typing import TypeVar
from typing import Union

import numpy as np
import pandas as pd
import pandas_market_calendars as tc
import pytz
import yfinance as yf
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.action_chains import ActionChains
from selenium.webdriver.common.by import By
from stockstats import StockDataFrame as Sdf
from webdriver_manager.chrome import ChromeDriverManager

### ä»¥ä¸‹éƒ¨åˆ†ç”± aymeric75 æ·»åŠ ï¼Œç”¨äºŽç½‘é¡µçˆ¬è™«åŠŸèƒ½


class YahooFinanceProcessor:
    """
    Yahoo Finance æ•°æ®å¤„ç†å™¨
    
    è¿™ä¸ªç±»æä¾›äº†ä»ŽYahoo Finance APIèŽ·å–è‚¡ç¥¨æ•°æ®çš„å®Œæ•´è§£å†³æ–¹æ¡ˆã€‚
    Yahoo Financeæ˜¯æœ€å—æ¬¢è¿Žçš„å…è´¹é‡‘èžæ•°æ®æºï¼Œæä¾›å…¨çƒè‚¡ç¥¨å¸‚åœºçš„
    å®žæ—¶å’ŒåŽ†å²æ•°æ®ã€‚
    
    ä¸»è¦ç‰¹ç‚¹ï¼š
    1. å…è´¹ä½¿ç”¨ï¼šæ— éœ€APIå¯†é’¥ï¼Œå¼€ç®±å³ç”¨
    2. æ•°æ®ä¸°å¯Œï¼šæ”¯æŒå…¨çƒä¸»è¦äº¤æ˜“æ‰€çš„è‚¡ç¥¨æ•°æ®
    3. æ—¶é—´ç²’åº¦çµæ´»ï¼šä»Ž1åˆ†é’Ÿåˆ°1æœˆçš„å¤šç§æ—¶é—´é—´éš”
    4. å®žæ—¶æ›´æ–°ï¼šæä¾›å‡†å®žæ—¶çš„å¸‚åœºæ•°æ®
    5. æŠ€æœ¯æŒ‡æ ‡é›†æˆï¼šå†…ç½®å¤šç§æŠ€æœ¯åˆ†æžæŒ‡æ ‡
    
    æ•°æ®è´¨é‡è¯´æ˜Žï¼š
    - å®žæ—¶æ€§ï¼šæœ‰15-20åˆ†é’Ÿå»¶è¿Ÿï¼ˆå…è´¹ç‰ˆé™åˆ¶ï¼‰
    - å‡†ç¡®æ€§ï¼šæ•°æ®è´¨é‡é«˜ï¼Œé€‚åˆç ”ç©¶å’Œå›žæµ‹
    - å®Œæ•´æ€§ï¼šå¶å°”å¯èƒ½æœ‰ç¼ºå¤±æ•°æ®ï¼Œéœ€è¦æ¸…æ´—å¤„ç†
    - ç¨³å®šæ€§ï¼šä½œä¸ºå…è´¹æœåŠ¡ï¼Œå¯èƒ½æœ‰è®¿é—®é™åˆ¶
    
    ä½¿ç”¨åœºæ™¯ï¼š
    - å­¦æœ¯ç ”ç©¶ï¼šå…è´¹èŽ·å–åŽ†å²æ•°æ®è¿›è¡Œå­¦æœ¯åˆ†æž
    - ç­–ç•¥å›žæµ‹ï¼šéªŒè¯äº¤æ˜“ç­–ç•¥çš„åŽ†å²è¡¨çŽ°
    - æ¨¡åž‹è®­ç»ƒï¼šä¸ºæœºå™¨å­¦ä¹ æ¨¡åž‹æä¾›è®­ç»ƒæ•°æ®
    - å®žæ—¶ç›‘æŽ§ï¼šå¼€å‘è‚¡ç¥¨ç›‘æŽ§å’Œåˆ†æžå·¥å…·
    """

    def __init__(self):
        """
        åˆå§‹åŒ–Yahoo Financeå¤„ç†å™¨
        
        Yahoo Finance APIæ˜¯åŸºäºŽHTTPè¯·æ±‚çš„ï¼Œä¸éœ€è¦è®¤è¯ï¼Œ
        å› æ­¤åˆå§‹åŒ–è¿‡ç¨‹å¾ˆç®€å•ï¼Œä¸»è¦æ˜¯è®¾ç½®é»˜è®¤å‚æ•°ã€‚
        """
        print("ðŸŒ åˆå§‹åŒ–Yahoo Financeæ•°æ®å¤„ç†å™¨")
        print("  âœ… æ— éœ€APIå¯†é’¥ï¼Œå¼€ç®±å³ç”¨")
        pass

    """
    æ•°æ®ä¸‹è½½æ–¹æ³•è¯´æ˜Ž
    
    å‚æ•°è¯´æ˜Žï¼š
    ----------
        start_date : str
            æ•°æ®å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼ï¼š'YYYY-MM-DD'
        end_date : str
            æ•°æ®ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ï¼š'YYYY-MM-DD'
        ticker_list : list
            è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼Œå¦‚['AAPL', 'MSFT', 'GOOGL']
        time_interval : str
            æ—¶é—´é—´éš”ï¼Œæ”¯æŒï¼š1m, 5m, 15m, 30m, 1h, 1d, 1wk, 1mo
    
    ç¤ºä¾‹ï¼š
    -------
    è¾“å…¥å‚æ•°ï¼š
    ticker_list = ['AAPL', 'MSFT', 'GOOGL']
    start_date = '2020-01-01'
    end_date = '2021-12-31'
    time_interval = "1D"  # æ—¥çº¿æ•°æ®

    è¾“å‡ºæ•°æ®æ ¼å¼ï¼š
        date        tic     open        high        low         close       volume
    0   2020-01-02  AAPL    74.059998   75.150002   73.797501   75.087502   135480400.0
    1   2020-01-02  MSFT    157.320007  158.139999  155.509995  156.529999   22834900.0
    2   2020-01-02  GOOGL   1347.010010 1347.010010 1337.000000 1339.390015   1715200.0
    ...
    
    æ•°æ®åˆ—è¯´æ˜Žï¼š
    - date: äº¤æ˜“æ—¥æœŸ
    - tic: è‚¡ç¥¨ä»£ç ï¼ˆticker symbolï¼‰
    - open: å¼€ç›˜ä»·
    - high: æœ€é«˜ä»·
    - low: æœ€ä½Žä»·
    - close: æ”¶ç›˜ä»·
    - volume: æˆäº¤é‡
    """

    ######## ä»¥ä¸‹ä»£ç ç”± aymeric75 æ·»åŠ  ###################

    def date_to_unix(self, date_str) -> int:
        """
        å°†æ—¥æœŸå­—ç¬¦ä¸²è½¬æ¢ä¸ºUnixæ—¶é—´æˆ³
        
        Unixæ—¶é—´æˆ³æ˜¯ä»Ž1970å¹´1æœˆ1æ—¥å¼€å§‹çš„ç§’æ•°ï¼Œåœ¨ç½‘ç»œAPIä¸­å¹¿æ³›ä½¿ç”¨ã€‚
        Yahoo Financeçš„æŸäº›APIæŽ¥å£éœ€è¦Unixæ—¶é—´æˆ³æ ¼å¼çš„æ—¥æœŸå‚æ•°ã€‚
        
        Args:
            date_str (str): æ—¥æœŸå­—ç¬¦ä¸²ï¼Œæ ¼å¼ä¸º'YYYY-MM-DD'
        
        Returns:
            int: Unixæ—¶é—´æˆ³ï¼ˆç§’ï¼‰
        
        ç¤ºä¾‹ï¼š
            '2020-01-01' -> 1577836800
        """
        dt = datetime.datetime.strptime(date_str, "%Y-%m-%d")
        return int(dt.timestamp())

    def fetch_stock_data(self, stock_name, period1, period2) -> pd.DataFrame:
        """
        ä½¿ç”¨ç½‘é¡µçˆ¬è™«èŽ·å–å•åªè‚¡ç¥¨çš„åŽ†å²æ•°æ®
        
        è¿™ä¸ªæ–¹æ³•é€šè¿‡Seleniumè‡ªåŠ¨åŒ–æµè§ˆå™¨æ¥çˆ¬å–Yahoo Financeç½‘é¡µä¸Šçš„
        è‚¡ç¥¨åŽ†å²æ•°æ®ã€‚å½“APIè®¿é—®å—é™æ—¶ï¼Œè¿™ç§æ–¹æ³•å¯ä»¥ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆã€‚
        
        æŠ€æœ¯å®žçŽ°ï¼š
        1. ä½¿ç”¨Seleniumå¯åŠ¨æ— å¤´Chromeæµè§ˆå™¨
        2. è®¿é—®Yahoo FinanceåŽ†å²æ•°æ®é¡µé¢
        3. å¤„ç†å¯èƒ½çš„å¼¹çª—å’Œå¹¿å‘Š
        4. è§£æžHTMLè¡¨æ ¼æ•°æ®
        5. è½¬æ¢ä¸ºpandas DataFrameæ ¼å¼
        
        Args:
            stock_name (str): è‚¡ç¥¨ä»£ç ï¼Œå¦‚'AAPL'
            period1 (int): å¼€å§‹æ—¶é—´çš„Unixæ—¶é—´æˆ³
            period2 (int): ç»“æŸæ—¶é—´çš„Unixæ—¶é—´æˆ³
        
        Returns:
            pd.DataFrame: åŒ…å«åŽ†å²ä»·æ ¼æ•°æ®çš„DataFrame
        
        æ³¨æ„ï¼š
        - ç½‘é¡µçˆ¬è™«å¯èƒ½ä¸ç¨³å®šï¼Œå»ºè®®ä¼˜å…ˆä½¿ç”¨APIæ–¹æ³•
        - éœ€è¦å®‰è£…Chromeæµè§ˆå™¨å’ŒChromeDriver
        - çˆ¬è™«é€Ÿåº¦è¾ƒæ…¢ï¼Œä¸é€‚åˆå¤§é‡æ•°æ®èŽ·å–
        """
        print(f"  ðŸ•·ï¸ çˆ¬å–{stock_name}çš„åŽ†å²æ•°æ®...")
        
        # æž„å»ºYahoo FinanceåŽ†å²æ•°æ®é¡µé¢URL
        url = f"https://finance.yahoo.com/quote/{stock_name}/history/?period1={period1}&period2={period2}&filter=history"

        # Selenium WebDriver è®¾ç½®
        options = Options()
        options.add_argument("--headless")  # æ— å¤´æ¨¡å¼ï¼Œæé«˜æ€§èƒ½
        options.add_argument("--disable-gpu")  # ç¦ç”¨GPUï¼Œæé«˜å…¼å®¹æ€§
        driver = webdriver.Chrome(
            service=Service(ChromeDriverManager().install()), options=options
        )

        try:
            # è®¿é—®URL
            driver.get(url)
            driver.maximize_window()
            time.sleep(5)  # ç­‰å¾…é¡µé¢åŠ è½½

            # å¤„ç†å¯èƒ½çš„CookieåŒæ„å¼¹çª—
            try:
                RejectAll = driver.find_element(
                    By.XPATH, '//button[@class="btn secondary reject-all"]'
                )
                action = ActionChains(driver)
                action.click(on_element=RejectAll)
                action.perform()
                time.sleep(5)
                print("    âœ… å·²å¤„ç†Cookieå¼¹çª—")

            except Exception as e:
                print(f"    â„¹ï¸ æœªå‘çŽ°å¼¹çª—æˆ–å¤„ç†å¤±è´¥: {e}")

            # è§£æžé¡µé¢èŽ·å–æ•°æ®è¡¨æ ¼
            soup = BeautifulSoup(driver.page_source, "html.parser")
            table = soup.find("table")
            if not table:
                raise Exception("æœªæ‰¾åˆ°æ•°æ®è¡¨æ ¼")

            # æå–è¡¨å¤´
            headers = [th.text.strip() for th in table.find_all("th")]
            headers[4] = "Close"        # ä¿®æ­£æ”¶ç›˜ä»·åˆ—å
            headers[5] = "Adj Close"    # ä¿®æ­£è°ƒæ•´æ”¶ç›˜ä»·åˆ—å
            headers = ["date", "open", "high", "low", "close", "adjcp", "volume"]

            # æå–æ•°æ®è¡Œ
            rows = []
            for tr in table.find_all("tr")[1:]:  # è·³è¿‡è¡¨å¤´è¡Œ
                cells = [td.text.strip() for td in tr.find_all("td")]
                if len(cells) == len(headers):  # åªæ·»åŠ åˆ—æ•°æ­£ç¡®çš„è¡Œ
                    rows.append(cells)

            # åˆ›å»ºDataFrame
            df = pd.DataFrame(rows, columns=headers)

            # æ•°æ®ç±»åž‹è½¬æ¢å‡½æ•°
            def safe_convert(value, dtype):
                """å®‰å…¨è½¬æ¢æ•°æ®ç±»åž‹ï¼Œå¤„ç†æ ¼å¼åŒ–æ•°å­—ï¼ˆå¦‚åŒ…å«é€—å·çš„æ•°å­—ï¼‰"""
                try:
                    return dtype(value.replace(",", ""))
                except ValueError:
                    return value

            # è½¬æ¢æ•°å€¼åˆ—çš„æ•°æ®ç±»åž‹
            df["open"] = df["open"].apply(lambda x: safe_convert(x, float))
            df["high"] = df["high"].apply(lambda x: safe_convert(x, float))
            df["low"] = df["low"].apply(lambda x: safe_convert(x, float))
            df["close"] = df["close"].apply(lambda x: safe_convert(x, float))
            df["adjcp"] = df["adjcp"].apply(lambda x: safe_convert(x, float))
            df["volume"] = df["volume"].apply(lambda x: safe_convert(x, int))

            # æ·»åŠ è‚¡ç¥¨ä»£ç åˆ—
            df["tic"] = stock_name

            # æ·»åŠ äº¤æ˜“æ—¥åºå·åˆ—
            start_date = datetime.datetime.fromtimestamp(period1)
            df["date"] = pd.to_datetime(df["date"])
            df["day"] = (df["date"] - start_date).dt.days
            df = df[df["day"] >= 0]  # æŽ’é™¤å¼€å§‹æ—¥æœŸä¹‹å‰çš„æ•°æ®

            # åè½¬DataFrameè¡Œåºï¼ˆYahooè¿”å›žçš„æ•°æ®æ˜¯å€’åºçš„ï¼‰
            df = df.iloc[::-1].reset_index(drop=True)

            print(f"    âœ… æˆåŠŸèŽ·å–{len(df)}æ¡{stock_name}æ•°æ®è®°å½•")
            return df
            
        finally:
            # ç¡®ä¿æµè§ˆå™¨è¢«å…³é—­
            driver.quit()

    def scrap_data(self, stock_names, start_date, end_date) -> pd.DataFrame:
        """
        æ‰¹é‡çˆ¬å–å¤šåªè‚¡ç¥¨çš„åŽ†å²æ•°æ®
        
        è¿™ä¸ªæ–¹æ³•å¯¹å¤šåªè‚¡ç¥¨æ‰§è¡Œç½‘é¡µçˆ¬è™«ï¼ŒèŽ·å–å®ƒä»¬çš„åŽ†å²æ•°æ®ï¼Œ
        ç„¶åŽåˆå¹¶æˆä¸€ä¸ªç»Ÿä¸€çš„DataFrameã€‚
        
        Args:
            stock_names (list): è‚¡ç¥¨ä»£ç åˆ—è¡¨
            start_date (str): å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼'YYYY-MM-DD'
            end_date (str): ç»“æŸæ—¥æœŸï¼Œæ ¼å¼'YYYY-MM-DD'
        
        Returns:
            pd.DataFrame: åˆå¹¶åŽçš„æ‰€æœ‰è‚¡ç¥¨åŽ†å²æ•°æ®
        
        å¤„ç†æµç¨‹ï¼š
        1. è½¬æ¢æ—¥æœŸä¸ºUnixæ—¶é—´æˆ³
        2. é€åªè‚¡ç¥¨è¿›è¡Œæ•°æ®çˆ¬å–
        3. åˆå¹¶æ‰€æœ‰è‚¡ç¥¨çš„æ•°æ®
        4. æŒ‰æ—¥æœŸå’Œè‚¡ç¥¨ä»£ç æŽ’åº
        
        æ³¨æ„ï¼š
        - çˆ¬è™«è¿‡ç¨‹å¯èƒ½è¾ƒæ…¢ï¼Œè¯·è€å¿ƒç­‰å¾…
        - éƒ¨åˆ†è‚¡ç¥¨å¯èƒ½çˆ¬å–å¤±è´¥ï¼Œä¼šè·³è¿‡å¹¶ç»§ç»­
        - å»ºè®®ä¸è¦åŒæ—¶çˆ¬å–è¿‡å¤šè‚¡ç¥¨ï¼Œé¿å…è¢«ç½‘ç«™é™åˆ¶
        """
        print(f"ðŸ•·ï¸ å¼€å§‹æ‰¹é‡çˆ¬å–{len(stock_names)}åªè‚¡ç¥¨æ•°æ®...")
        
        # è½¬æ¢æ—¥æœŸæ ¼å¼
        period1 = self.date_to_unix(start_date)
        period2 = self.date_to_unix(end_date)

        all_dataframes = []
        total_stocks = len(stock_names)

        # é€åªå¤„ç†è‚¡ç¥¨
        for i, stock_name in enumerate(stock_names):
            try:
                print(
                    f"æ­£åœ¨å¤„ç† {stock_name} ({i + 1}/{total_stocks})... "
                    f"è¿›åº¦: {(i + 1) / total_stocks * 100:.1f}%"
                )
                df = self.fetch_stock_data(stock_name, period1, period2)
                all_dataframes.append(df)
                
            except Exception as e:
                print(f"âŒ èŽ·å–{stock_name}æ•°æ®å¤±è´¥: {e}")

        # åˆå¹¶æ‰€æœ‰æ•°æ®
        if all_dataframes:
            combined_df = pd.concat(all_dataframes, ignore_index=True)
            combined_df = combined_df.sort_values(by=["day", "tic"]).reset_index(drop=True)
            print(f"âœ… æˆåŠŸçˆ¬å–å¹¶åˆå¹¶{len(combined_df)}æ¡æ•°æ®è®°å½•")
            return combined_df
        else:
            print("âŒ æœªèƒ½èŽ·å–ä»»ä½•è‚¡ç¥¨æ•°æ®")
            return pd.DataFrame()

    ######## aymeric75 æ·»åŠ çš„ä»£ç ç»“æŸ ###################

    def convert_interval(self, time_interval: str) -> str:
        """
        è½¬æ¢æ—¶é—´é—´éš”æ ¼å¼
        
        å°†FinRLæ ‡å‡†åŒ–çš„æ—¶é—´å‘¨æœŸè½¬æ¢ä¸ºYahoo Finance APIæ”¯æŒçš„æ ¼å¼ã€‚
        ä¸åŒçš„æ•°æ®æºå¯¹æ—¶é—´é—´éš”æœ‰ä¸åŒçš„è¡¨ç¤ºæ–¹æ³•ï¼Œè¿™ä¸ªå‡½æ•°ç¡®ä¿å…¼å®¹æ€§ã€‚
        
        Args:
            time_interval (str): FinRLæ ¼å¼çš„æ—¶é—´é—´éš”
        
        Returns:
            str: Yahoo Finance APIæ ¼å¼çš„æ—¶é—´é—´éš”
        
        æ”¯æŒçš„æ—¶é—´é—´éš”ï¼š
        - åˆ†é’Ÿçº§ï¼š1m, 2m, 5m, 15m, 30m, 60m, 90m
        - å°æ—¶çº§ï¼š1h
        - æ—¥çº§ï¼š1d, 5d
        - å‘¨çº§ï¼š1wk
        - æœˆçº§ï¼š1mo, 3mo
        
        ä½¿ç”¨è¯´æ˜Žï¼š
        - 1måˆ°30mï¼šé€‚ç”¨äºŽçŸ­çº¿äº¤æ˜“å’Œé«˜é¢‘ç­–ç•¥
        - 1håˆ°1dï¼šé€‚ç”¨äºŽæ—¥å†…äº¤æ˜“ç­–ç•¥
        - 1wkåˆ°1moï¼šé€‚ç”¨äºŽä¸­é•¿æœŸæŠ•èµ„ç­–ç•¥
        """
        # Yahoo Financeæ”¯æŒçš„æ‰€æœ‰æ—¶é—´é—´éš”
        yahoo_intervals = [
            "1m",    # 1åˆ†é’Ÿ - è¶…çŸ­çº¿äº¤æ˜“
            "2m",    # 2åˆ†é’Ÿ
            "5m",    # 5åˆ†é’Ÿ - çŸ­çº¿äº¤æ˜“å¸¸ç”¨
            "15m",   # 15åˆ†é’Ÿ - æ—¥å†…äº¤æ˜“å¸¸ç”¨
            "30m",   # 30åˆ†é’Ÿ
            "60m",   # 60åˆ†é’Ÿ = 1å°æ—¶
            "90m",   # 90åˆ†é’Ÿ
            "1h",    # 1å°æ—¶ - æ—¥å†…ç­–ç•¥
            "1d",    # 1å¤© - æœ€å¸¸ç”¨ï¼Œé€‚åˆä¸­é•¿æœŸåˆ†æž
            "5d",    # 5å¤©
            "1wk",   # 1å‘¨ - å‘¨çº¿åˆ†æž
            "1mo",   # 1æœˆ - æœˆçº¿åˆ†æž
            "3mo",   # 3æœˆ - å­£åº¦åˆ†æž
        ]
        
        if time_interval in yahoo_intervals:
            return time_interval
        if time_interval in [
            "1Min",
            "2Min",
            "5Min",
            "15Min",
            "30Min",
            "60Min",
            "90Min",
        ]:
            time_interval = time_interval.replace("Min", "m")
        elif time_interval in ["1H", "1D", "5D", "1h", "1d", "5d"]:
            time_interval = time_interval.lower()
        elif time_interval == "1W":
            time_interval = "1wk"
        elif time_interval in ["1M", "3M"]:
            time_interval = time_interval.replace("M", "mo")
        else:
            raise ValueError("wrong time_interval")

        return time_interval

    def download_data(
        self,
        ticker_list: list[str],
        start_date: str,
        end_date: str,
        time_interval: str,
        proxy: str | dict = None,
    ) -> pd.DataFrame:
        time_interval = self.convert_interval(time_interval)

        self.start = start_date
        self.end = end_date
        self.time_interval = time_interval

        # Download and save the data in a pandas DataFrame
        start_date = pd.Timestamp(start_date)
        end_date = pd.Timestamp(end_date)
        delta = timedelta(days=1)
        data_df = pd.DataFrame()
        for tic in ticker_list:
            current_tic_start_date = start_date
            while (
                current_tic_start_date <= end_date
            ):  # downloading daily to workaround yfinance only allowing  max 7 calendar (not trading) days of 1 min data per single download
                temp_df = yf.download(
                    tic,
                    start=current_tic_start_date,
                    end=current_tic_start_date + delta,
                    interval=self.time_interval,
                    proxy=proxy,
                )
                if temp_df.columns.nlevels != 1:
                    temp_df.columns = temp_df.columns.droplevel(1)

                temp_df["tic"] = tic
                data_df = pd.concat([data_df, temp_df])
                current_tic_start_date += delta

        data_df = data_df.reset_index().drop(columns=["Adj Close"])
        # convert the column names to match processor_alpaca.py as far as poss
        data_df.columns = [
            "timestamp",
            "close",
            "high",
            "low",
            "open",
            "volume",
            "tic",
        ]

        return data_df

    def clean_data(self, df: pd.DataFrame) -> pd.DataFrame:
        tic_list = np.unique(df.tic.values)
        NY = "America/New_York"

        trading_days = self.get_trading_days(start=self.start, end=self.end)
        # produce full timestamp index
        if self.time_interval == "1d":
            times = trading_days
        elif self.time_interval == "1m":
            times = []
            for day in trading_days:
                #                NY = "America/New_York"
                current_time = pd.Timestamp(day + " 09:30:00").tz_localize(NY)
                for i in range(390):  # 390 minutes in trading day
                    times.append(current_time)
                    current_time += pd.Timedelta(minutes=1)
        else:
            raise ValueError(
                "Data clean at given time interval is not supported for YahooFinance data."
            )

        # create a new dataframe with full timestamp series
        new_df = pd.DataFrame()
        for tic in tic_list:
            tmp_df = pd.DataFrame(
                columns=["open", "high", "low", "close", "volume"], index=times
            )
            tic_df = df[
                df.tic == tic
            ]  # extract just the rows from downloaded data relating to this tic
            for i in range(tic_df.shape[0]):  # fill empty DataFrame using original data
                tmp_timestamp = tic_df.iloc[i]["timestamp"]
                if tmp_timestamp.tzinfo is None:
                    tmp_timestamp = tmp_timestamp.tz_localize(NY)
                else:
                    tmp_timestamp = tmp_timestamp.tz_convert(NY)
                tmp_df.loc[tmp_timestamp] = tic_df.iloc[i][
                    ["open", "high", "low", "close", "volume"]
                ]
            # print("(9) tmp_df\n", tmp_df.to_string()) # print ALL dataframe to check for missing rows from download

            # if close on start date is NaN, fill data with first valid close
            # and set volume to 0.
            if str(tmp_df.iloc[0]["close"]) == "nan":
                print("NaN data on start date, fill using first valid data.")
                for i in range(tmp_df.shape[0]):
                    if str(tmp_df.iloc[i]["close"]) != "nan":
                        first_valid_close = tmp_df.iloc[i]["close"]
                        tmp_df.iloc[0] = [
                            first_valid_close,
                            first_valid_close,
                            first_valid_close,
                            first_valid_close,
                            0.0,
                        ]
                        break

            # if the close price of the first row is still NaN (All the prices are NaN in this case)
            if str(tmp_df.iloc[0]["close"]) == "nan":
                print(
                    "Missing data for ticker: ",
                    tic,
                    " . The prices are all NaN. Fill with 0.",
                )
                tmp_df.iloc[0] = [
                    0.0,
                    0.0,
                    0.0,
                    0.0,
                    0.0,
                ]

            # fill NaN data with previous close and set volume to 0.
            for i in range(tmp_df.shape[0]):
                if str(tmp_df.iloc[i]["close"]) == "nan":
                    previous_close = tmp_df.iloc[i - 1]["close"]
                    if str(previous_close) == "nan":
                        raise ValueError
                    tmp_df.iloc[i] = [
                        previous_close,
                        previous_close,
                        previous_close,
                        previous_close,
                        0.0,
                    ]
                    # print(tmp_df.iloc[i], " Filled NaN data with previous close and set volume to 0. ticker: ", tic)

            # merge single ticker data to new DataFrame
            tmp_df = tmp_df.astype(float)
            tmp_df["tic"] = tic
            new_df = pd.concat([new_df, tmp_df])

        #            print(("Data clean for ") + tic + (" is finished."))

        # reset index and rename columns
        new_df = new_df.reset_index()
        new_df = new_df.rename(columns={"index": "timestamp"})

        #        print("Data clean all finished!")

        return new_df

    def add_technical_indicator(
        self, data: pd.DataFrame, tech_indicator_list: list[str]
    ):
        """
        calculate technical indicators
        use stockstats package to add technical inidactors
        :param data: (df) pandas dataframe
        :return: (df) pandas dataframe
        """
        df = data.copy()
        df = df.sort_values(by=["tic", "timestamp"])
        stock = Sdf.retype(df.copy())
        unique_ticker = stock.tic.unique()

        for indicator in tech_indicator_list:
            indicator_df = pd.DataFrame()
            for i in range(len(unique_ticker)):
                try:
                    temp_indicator = stock[stock.tic == unique_ticker[i]][indicator]
                    temp_indicator = pd.DataFrame(temp_indicator)
                    temp_indicator["tic"] = unique_ticker[i]
                    temp_indicator["timestamp"] = df[df.tic == unique_ticker[i]][
                        "timestamp"
                    ].to_list()
                    indicator_df = pd.concat(
                        [indicator_df, temp_indicator], ignore_index=True
                    )
                except Exception as e:
                    print(e)
            df = df.merge(
                indicator_df[["tic", "timestamp", indicator]],
                on=["tic", "timestamp"],
                how="left",
            )
        df = df.sort_values(by=["timestamp", "tic"])
        return df

    def add_vix(self, data: pd.DataFrame) -> pd.DataFrame:
        """
        add vix from yahoo finance
        :param data: (df) pandas dataframe
        :return: (df) pandas dataframe
        """
        vix_df = self.download_data(["VIXY"], self.start, self.end, self.time_interval)
        cleaned_vix = self.clean_data(vix_df)
        print("cleaned_vix\n", cleaned_vix)
        vix = cleaned_vix[["timestamp", "close"]]
        print('cleaned_vix[["timestamp", "close"]\n', vix)
        vix = vix.rename(columns={"close": "VIXY"})
        print('vix.rename(columns={"close": "VIXY"}\n', vix)

        df = data.copy()
        print("df\n", df)
        df = df.merge(vix, on="timestamp")
        df = df.sort_values(["timestamp", "tic"]).reset_index(drop=True)
        return df

    def calculate_turbulence(
        self, data: pd.DataFrame, time_period: int = 252
    ) -> pd.DataFrame:
        # can add other market assets
        df = data.copy()
        df_price_pivot = df.pivot(index="timestamp", columns="tic", values="close")
        # use returns to calculate turbulence
        df_price_pivot = df_price_pivot.pct_change()

        unique_date = df.timestamp.unique()
        # start after a fixed timestamp period
        start = time_period
        turbulence_index = [0] * start
        # turbulence_index = [0]
        count = 0
        for i in range(start, len(unique_date)):
            current_price = df_price_pivot[df_price_pivot.index == unique_date[i]]
            # use one year rolling window to calcualte covariance
            hist_price = df_price_pivot[
                (df_price_pivot.index < unique_date[i])
                & (df_price_pivot.index >= unique_date[i - time_period])
            ]
            # Drop tickers which has number missing values more than the "oldest" ticker
            filtered_hist_price = hist_price.iloc[
                hist_price.isna().sum().min() :
            ].dropna(axis=1)

            cov_temp = filtered_hist_price.cov()
            current_temp = current_price[[x for x in filtered_hist_price]] - np.mean(
                filtered_hist_price, axis=0
            )
            temp = current_temp.values.dot(np.linalg.pinv(cov_temp)).dot(
                current_temp.values.T
            )
            if temp > 0:
                count += 1
                if count > 2:
                    turbulence_temp = temp[0][0]
                else:
                    # avoid large outlier because of the calculation just begins
                    turbulence_temp = 0
            else:
                turbulence_temp = 0
            turbulence_index.append(turbulence_temp)

        turbulence_index = pd.DataFrame(
            {"timestamp": df_price_pivot.index, "turbulence": turbulence_index}
        )
        return turbulence_index

    def add_turbulence(
        self, data: pd.DataFrame, time_period: int = 252
    ) -> pd.DataFrame:
        """
        add turbulence index from a precalcualted dataframe
        :param data: (df) pandas dataframe
        :return: (df) pandas dataframe
        """
        df = data.copy()
        turbulence_index = self.calculate_turbulence(df, time_period=time_period)
        df = df.merge(turbulence_index, on="timestamp")
        df = df.sort_values(["timestamp", "tic"]).reset_index(drop=True)
        return df

    def df_to_array(
        self, df: pd.DataFrame, tech_indicator_list: list[str], if_vix: bool
    ) -> list[np.ndarray]:
        df = df.copy()
        unique_ticker = df.tic.unique()
        if_first_time = True
        for tic in unique_ticker:
            if if_first_time:
                price_array = df[df.tic == tic][["close"]].values
                tech_array = df[df.tic == tic][tech_indicator_list].values
                if if_vix:
                    turbulence_array = df[df.tic == tic]["VIXY"].values
                else:
                    turbulence_array = df[df.tic == tic]["turbulence"].values
                if_first_time = False
            else:
                price_array = np.hstack(
                    [price_array, df[df.tic == tic][["close"]].values]
                )
                tech_array = np.hstack(
                    [tech_array, df[df.tic == tic][tech_indicator_list].values]
                )
        #        print("Successfully transformed into array")
        return price_array, tech_array, turbulence_array

    def get_trading_days(self, start: str, end: str) -> list[str]:
        nyse = tc.get_calendar("NYSE")
        df = nyse.date_range_htf("1D", pd.Timestamp(start), pd.Timestamp(end))
        trading_days = []
        for day in df:
            trading_days.append(str(day)[:10])
        return trading_days

    # ****** NB: YAHOO FINANCE DATA MAY BE IN REAL-TIME OR DELAYED BY 15 MINUTES OR MORE, DEPENDING ON THE EXCHANGE ******
    def fetch_latest_data(
        self,
        ticker_list: list[str],
        time_interval: str,
        tech_indicator_list: list[str],
        limit: int = 100,
    ) -> pd.DataFrame:
        time_interval = self.convert_interval(time_interval)

        end_datetime = datetime.datetime.now()
        start_datetime = end_datetime - datetime.timedelta(
            minutes=limit + 1
        )  # get the last rows up to limit

        data_df = pd.DataFrame()
        for tic in ticker_list:
            barset = yf.download(
                tic, start_datetime, end_datetime, interval=time_interval
            )  # use start and end datetime to simulate the limit parameter
            barset["tic"] = tic
            data_df = pd.concat([data_df, barset])

        data_df = data_df.reset_index().drop(
            columns=["Adj Close"]
        )  # Alpaca data does not have 'Adj Close'

        data_df.columns = [  # convert to Alpaca column names lowercase
            "timestamp",
            "open",
            "high",
            "low",
            "close",
            "volume",
            "tic",
        ]

        start_time = data_df.timestamp.min()
        end_time = data_df.timestamp.max()
        times = []
        current_time = start_time
        end = end_time + pd.Timedelta(minutes=1)
        while current_time != end:
            times.append(current_time)
            current_time += pd.Timedelta(minutes=1)

        df = data_df.copy()
        new_df = pd.DataFrame()
        for tic in ticker_list:
            tmp_df = pd.DataFrame(
                columns=["open", "high", "low", "close", "volume"], index=times
            )
            tic_df = df[df.tic == tic]
            for i in range(tic_df.shape[0]):
                tmp_df.loc[tic_df.iloc[i]["timestamp"]] = tic_df.iloc[i][
                    ["open", "high", "low", "close", "volume"]
                ]

                if str(tmp_df.iloc[0]["close"]) == "nan":
                    for i in range(tmp_df.shape[0]):
                        if str(tmp_df.iloc[i]["close"]) != "nan":
                            first_valid_close = tmp_df.iloc[i]["close"]
                            tmp_df.iloc[0] = [
                                first_valid_close,
                                first_valid_close,
                                first_valid_close,
                                first_valid_close,
                                0.0,
                            ]
                            break
                if str(tmp_df.iloc[0]["close"]) == "nan":
                    print(
                        "Missing data for ticker: ",
                        tic,
                        " . The prices are all NaN. Fill with 0.",
                    )
                    tmp_df.iloc[0] = [
                        0.0,
                        0.0,
                        0.0,
                        0.0,
                        0.0,
                    ]

            for i in range(tmp_df.shape[0]):
                if str(tmp_df.iloc[i]["close"]) == "nan":
                    previous_close = tmp_df.iloc[i - 1]["close"]
                    if str(previous_close) == "nan":
                        previous_close = 0.0
                    tmp_df.iloc[i] = [
                        previous_close,
                        previous_close,
                        previous_close,
                        previous_close,
                        0.0,
                    ]
            tmp_df = tmp_df.astype(float)
            tmp_df["tic"] = tic
            new_df = pd.concat([new_df, tmp_df])

        new_df = new_df.reset_index()
        new_df = new_df.rename(columns={"index": "timestamp"})

        df = self.add_technical_indicator(new_df, tech_indicator_list)
        df["VIXY"] = 0

        price_array, tech_array, turbulence_array = self.df_to_array(
            df, tech_indicator_list, if_vix=True
        )
        latest_price = price_array[-1]
        latest_tech = tech_array[-1]
        start_datetime = end_datetime - datetime.timedelta(minutes=1)
        turb_df = yf.download("VIXY", start_datetime, limit=1)
        latest_turb = turb_df["Close"].values
        return latest_price, latest_tech, latest_turb
